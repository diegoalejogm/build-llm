{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb8ef53b",
   "metadata": {},
   "source": [
    "# Instruction Tuning the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47868b1",
   "metadata": {},
   "source": [
    "### Download Instruction Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "233dcce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of entries: 1100\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import urllib\n",
    "\n",
    "\n",
    "def download_and_load_file(file_path, url):\n",
    "    if not os.path.exists(file_path):\n",
    "        with urllib.request.urlopen(url) as response:\n",
    "            text_data = response.read().decode(\"utf-8\")\n",
    "        with open(file_path, \"w\", encoding=\"utf-8\") as file:\n",
    "            file.write(text_data)\n",
    "    with open(file_path, \"r\") as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "\n",
    "file_path = \"instruction-data.json\"\n",
    "url = (\n",
    "    \"https://raw.githubusercontent.com/rasbt/LLMs-from-scratch\"\n",
    "    \"/main/ch07/01_main-chapter-code/instruction-data.json\"\n",
    ")\n",
    "\n",
    "data = download_and_load_file(file_path, url)\n",
    "print(\"Number of entries:\", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88b8190",
   "metadata": {},
   "source": [
    "Let's print one of the entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e237bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " {'instruction': 'Identify the correct spelling of the following word.', 'input': 'Ocassion', 'output': \"The correct spelling is 'Occasion.'\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", data[50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc93b88",
   "metadata": {},
   "source": [
    "##### TODO: Exercise 7.1 Changing prompt styles\n",
    "After fine-tuning the model with the Alpaca prompt style, try the Phi-3 prompt style\n",
    "shown in figure 7.4 and observe whether it affects the response quality of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f53227a",
   "metadata": {},
   "source": [
    "##### Implementing the prompt formatting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d03847f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(entry):\n",
    "    instruction = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately completes the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{entry['instruction']}\"\n",
    "    )\n",
    "    input = f\"\\n\\n### Input:\\n{entry['input']}\" if entry[\"input\"] else \"\"\n",
    "    return instruction + input\n",
    "\n",
    "\n",
    "def format_output(entry):\n",
    "    return f\"\\n\\n### Response:\\n{entry['output']}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085e3c6e",
   "metadata": {},
   "source": [
    "Let's thest the new function prompt formatting function on a dataset entry, and confirm its output is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f2ed346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Identify the correct spelling of the following word.\n",
      "\n",
      "### Input:\n",
      "Ocassion\n",
      "\n",
      "### Response:\n",
      "The correct spelling is 'Occasion.'\n"
     ]
    }
   ],
   "source": [
    "test_data = data[50]\n",
    "print(format_input(test_data) + format_output(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a873059",
   "metadata": {},
   "source": [
    "Let's thest the new function prompt formatting function on an entry that's missin the input field, and confirm it output is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a1c14bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert 45 kilometers to meters.\n",
      "\n",
      "### Response:\n",
      "45 kilometers is 45000 meters.\n"
     ]
    }
   ],
   "source": [
    "test_data = data[2]\n",
    "print(format_input(test_data) + format_output(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51ae0e5",
   "metadata": {},
   "source": [
    "##### Partitioning the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f43cd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set length: 935\n",
      "Validation set length: 55\n",
      "Test set length: 110\n"
     ]
    }
   ],
   "source": [
    "train_portion = int(len(data) * 0.85)\n",
    "test_portion = int(len(data) * 0.10)\n",
    "val_portion = len(data) - train_portion - test_portion\n",
    "\n",
    "train_data = data[:train_portion]\n",
    "test_data = data[train_portion : train_portion + test_portion]\n",
    "val_data = data[train_portion + test_portion :]\n",
    "\n",
    "print(\"Training set length:\", len(train_data))\n",
    "print(\"Validation set length:\", len(val_data))\n",
    "print(\"Test set length:\", len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3550c6d",
   "metadata": {},
   "source": [
    "### Organize Data into Training Batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67a24c0",
   "metadata": {},
   "source": [
    "Efficiently padding the data samples to equal lenghts in order to assemble multiple instruction examples in a batch.\n",
    "\n",
    "\n",
    "1. **Format data using prompt template**.\n",
    "2. **Tokenize formatted data**.\n",
    "3. **Adjust inputs to same lenght** with padding tokens.\n",
    "4. **Create target token IDs**, by shifting the inputs by 1.\n",
    "5. **Replace padding tokens with placeholders**, to exclude them from training loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b57829",
   "metadata": {},
   "source": [
    "##### Define Instruction Dataset\n",
    "That applies formatting and pretokenizes all inputs in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "916bf0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class InstructionDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer):\n",
    "        self.data = data\n",
    "        self.encoded_texts = []\n",
    "\n",
    "        for entry in data:\n",
    "            formatted_input = format_input(entry)\n",
    "            formatted_output = format_output(entry)\n",
    "            full_text = formatted_input + formatted_output\n",
    "            encoded_text = tokenizer.encode(full_text)\n",
    "\n",
    "            self.encoded_texts.append(encoded_text)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.encoded_texts[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7fdfdd",
   "metadata": {},
   "source": [
    "##### Tokenization\n",
    "\n",
    "Similar to the pre-training and classification fine-tuning, we use gpt tokenizer to encode the data, allowing for a special `eot` character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51da319b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f15cc5",
   "metadata": {},
   "source": [
    "##### Adjust inputs to the same lenght\n",
    "Define a collate function that adjusts inputs to the same lenght.\n",
    "\n",
    "A final version of the collate function will be used later on in the Dataloader to collate inputs into batches of the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d0cc23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_1(batch, pad_token_id=50256, device=\"cpu\"):\n",
    "    max_length = max(len(item) + 1 for item in batch)\n",
    "    inputs_lst = []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = new_item + [pad_token_id] * (max_length - len(new_item))\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        inputs_lst.append(inputs)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    return inputs_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7488403b",
   "metadata": {},
   "source": [
    "Let's test it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb409980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "batch = (inputs_1, inputs_2, inputs_3)\n",
    "print(custom_collate_draft_1(batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5356bb6e",
   "metadata": {},
   "source": [
    "As expected, the input with the longest length has no padding, whereas the other two inputs are padded to match the length of the first input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95beac5",
   "metadata": {},
   "source": [
    "##### Create Targets\n",
    "\n",
    "Let's update the collate function so we also compute the target tensors.\n",
    "\n",
    "The target tensors are the same as the input ones, shifted by one position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71d9da1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_draft_2(batch, pad_token_id=50256, device=\"cpu\"):\n",
    "    max_length = max(len(item) + 1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = new_item + [pad_token_id] * (max_length - len(new_item))\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "110eaf33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " : tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "Targets:\n",
      " : tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256, 50256, 50256, 50256],\n",
      "        [    8,     9, 50256, 50256, 50256]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "batch = (inputs_1, inputs_2, inputs_3)\n",
    "print(f\"Inputs:\\n : {custom_collate_draft_2(batch)[0]}\")\n",
    "print(f\"Targets:\\n : {custom_collate_draft_2(batch)[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a100d7",
   "metadata": {},
   "source": [
    "##### Replace padding tokens with placeholders\n",
    "\n",
    "This allows us to exclude all padding tokens from contributing to the loss calculation.\n",
    "\n",
    "- The default setting of the cross entropy function in PyTorch is cross_entropy(..., ignore_index=-100). This means that it ignores targets labeled with -100.\n",
    "- Retaining the `eot` token allows the LLM to learn when to generate an end- of-text token in response to instructions, which we use as an indicator that the generated response is complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49bd237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_collate_fn(\n",
    "    batch, pad_token_id=50256, ignore_index=-100, allowed_max_length=None, device=\"cpu\"\n",
    "):\n",
    "    max_length = max(len(item) + 1 for item in batch)\n",
    "    inputs_lst, targets_lst = [], []\n",
    "\n",
    "    for item in batch:\n",
    "        new_item = item.copy()\n",
    "        new_item += [pad_token_id]\n",
    "\n",
    "        padded = new_item + [pad_token_id] * (max_length - len(new_item))\n",
    "        inputs = torch.tensor(padded[:-1])\n",
    "        targets = torch.tensor(padded[1:])\n",
    "\n",
    "        # Replace extra padding tokens in targets by `ignore_index`.\n",
    "        mask = targets == pad_token_id\n",
    "        indices = torch.nonzero(mask).squeeze()\n",
    "        if indices.numel() > 1:\n",
    "            targets[indices[1:]] = ignore_index\n",
    "\n",
    "        if allowed_max_length is not None:\n",
    "            inputs = inputs[:allowed_max_length]\n",
    "            targets = targets[:allowed_max_length]\n",
    "\n",
    "        inputs_lst.append(inputs)\n",
    "        targets_lst.append(targets)\n",
    "\n",
    "    inputs_tensor = torch.stack(inputs_lst).to(device)\n",
    "    targets_tensor = torch.stack(targets_lst).to(device)\n",
    "    return inputs_tensor, targets_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b74d26",
   "metadata": {},
   "source": [
    "Let's test it now. \n",
    "\n",
    "We expect to see targets to have at most one padding token, and ignore tokens (-100) afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7243b06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " : tensor([[    0,     1,     2,     3,     4],\n",
      "        [    5,     6, 50256, 50256, 50256],\n",
      "        [    7,     8,     9, 50256, 50256]])\n",
      "Targets:\n",
      " : tensor([[    1,     2,     3,     4, 50256],\n",
      "        [    6, 50256,  -100,  -100,  -100],\n",
      "        [    8,     9, 50256,  -100,  -100]])\n"
     ]
    }
   ],
   "source": [
    "inputs_1 = [0, 1, 2, 3, 4]\n",
    "inputs_2 = [5, 6]\n",
    "inputs_3 = [7, 8, 9]\n",
    "batch = (inputs_1, inputs_2, inputs_3)\n",
    "print(f\"Inputs:\\n : {custom_collate_fn(batch)[0]}\")\n",
    "print(f\"Targets:\\n : {custom_collate_fn(batch)[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2127f141",
   "metadata": {},
   "source": [
    "It works as expected !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f089e87",
   "metadata": {},
   "source": [
    "##### Exercise 7.2 Instruction and input masking\n",
    "After completing the chapter and fine-tuning the model with InstructionDataset,\n",
    "replace the instruction and input tokens with the -100 mask to use the instruction\n",
    "masking method illustrated in figure 7.13. Then evaluate whether this has a positive\n",
    "effect on model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1debce",
   "metadata": {},
   "source": [
    "### Creating data loaders for an instruction dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b448d528",
   "metadata": {},
   "source": [
    "##### Set up device in Collate function.\n",
    "\n",
    "Moving the data into the device as part of the colalte function allows transfering the data outside of the training loop, preventing it from blocking the accelerator (GPU, TPU) during model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03c03d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: mps\n"
     ]
    }
   ],
   "source": [
    "def get_device():\n",
    "    device = \"cpu\"\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "    return device\n",
    "\n",
    "\n",
    "device = get_device()\n",
    "print(\"Device:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36825c3",
   "metadata": {},
   "source": [
    "We override the colalte function to set up the device and `max_length` to match the GPT2 max context length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b835795",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "custom_collate_fn = partial(custom_collate_fn, device=device, allowed_max_length=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee71f32",
   "metadata": {},
   "source": [
    "##### Create Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f6a90d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_dataset = InstructionDataset(train_data, tokenizer)\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=custom_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "val_dataset = InstructionDataset(val_data, tokenizer)\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=custom_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers,\n",
    ")\n",
    "test_dataset = InstructionDataset(test_data, tokenizer)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    collate_fn=custom_collate_fn,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    "    num_workers=num_workers,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f9b17d",
   "metadata": {},
   "source": [
    "Let's examine the size of the loader. \n",
    "\n",
    "We expect to see batches with different lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4276043e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 73]) torch.Size([8, 73])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 79]) torch.Size([8, 79])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 89]) torch.Size([8, 89])\n",
      "torch.Size([8, 59]) torch.Size([8, 59])\n",
      "torch.Size([8, 88]) torch.Size([8, 88])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 76]) torch.Size([8, 76])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 58]) torch.Size([8, 58])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 87]) torch.Size([8, 87])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 71]) torch.Size([8, 71])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 65]) torch.Size([8, 65])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 60]) torch.Size([8, 60])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 57]) torch.Size([8, 57])\n",
      "torch.Size([8, 72]) torch.Size([8, 72])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 62]) torch.Size([8, 62])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 70]) torch.Size([8, 70])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 80]) torch.Size([8, 80])\n",
      "torch.Size([8, 81]) torch.Size([8, 81])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 82]) torch.Size([8, 82])\n",
      "torch.Size([8, 63]) torch.Size([8, 63])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 68]) torch.Size([8, 68])\n",
      "torch.Size([8, 67]) torch.Size([8, 67])\n",
      "torch.Size([8, 77]) torch.Size([8, 77])\n",
      "torch.Size([8, 91]) torch.Size([8, 91])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 61]) torch.Size([8, 61])\n",
      "torch.Size([8, 75]) torch.Size([8, 75])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 78]) torch.Size([8, 78])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 64]) torch.Size([8, 64])\n",
      "torch.Size([8, 83]) torch.Size([8, 83])\n",
      "torch.Size([8, 66]) torch.Size([8, 66])\n",
      "torch.Size([8, 74]) torch.Size([8, 74])\n",
      "torch.Size([8, 69]) torch.Size([8, 69])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for inputs, targets in train_loader:\n",
    "    print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bda4ec",
   "metadata": {},
   "source": [
    "### Loading Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9e3aa465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      " Jiang exclude intensimet\n",
      " B LeavingACC Deng\n",
      "Mean:\n",
      "  tensor([-0.3596, -0.2606])\n",
      "Variance :\n",
      "  tensor([0.2015, 0.2673])\n",
      "Norm. Mean:\n",
      "  tensor([    -0.0000,      0.0000], grad_fn=<MeanBackward1>)\n",
      "Norm. Variance :\n",
      "  tensor([1.0000, 1.0000], grad_fn=<VarBackward0>)\n",
      "tensor([[0.2685, 0.7413],\n",
      "        [0.2738, 0.7564],\n",
      "        [0.2668, 0.7366],\n",
      "        [0.2618, 0.7218],\n",
      "        [0.2712, 0.7495]], grad_fn=<MmBackward0>)\n",
      "tensor([[-0.4927, -0.0791],\n",
      "        [-0.4938, -0.0806],\n",
      "        [-0.4924, -0.0851],\n",
      "        [-0.4923, -0.0819],\n",
      "        [-0.4928, -0.0853]], grad_fn=<MmBackward0>)\n",
      "Self Attention V2 output: \n",
      " tensor([[-0.4927, -0.0791],\n",
      "        [-0.4938, -0.0806],\n",
      "        [-0.4924, -0.0851],\n",
      "        [-0.4923, -0.0819],\n",
      "        [-0.4928, -0.0853]], grad_fn=<MmBackward0>)\n",
      "Self Attention V1 output: \n",
      " tensor([[-0.4927, -0.0791],\n",
      "        [-0.4938, -0.0806],\n",
      "        [-0.4924, -0.0851],\n",
      "        [-0.4923, -0.0819],\n",
      "        [-0.4928, -0.0853]], grad_fn=<MmBackward0>)\n",
      "batch.shape: torch.Size([2, 5, 3])\n",
      "contextVecs.shape: torch.Size([2, 5, 2])\n",
      "batch.shape: torch.Size([2, 5, 3])\n",
      "contextVecs.shape: torch.Size([2, 5, 4])\n",
      "batch.shape: torch.Size([2, 5, 3])\n",
      "contextVecs.shape: torch.Size([2, 5, 2])\n",
      "batch.shape: torch.Size([2, 1024, 768])\n",
      "contextVecs.shape: torch.Size([2, 1024, 768])\n",
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n",
      "Output: tensor([[15496,    11,   314,   716, 24111, 43446, 11311, 42014, 15660, 43819]])\n",
      "Output length: 10\n",
      "Hello, I amFrench rebirth chocolate horny incentiveliterally\n",
      "year 1122\n",
      "years 1123\n",
      "yellow 1124\n",
      "yet 1125\n",
      "you 1126\n",
      "younger 1127\n",
      "your 1128\n",
      "yourself 1129\n",
      "<|endoftext|> 1130\n",
      "<|unk|> 1131\n",
      "[999, 1131, 1131, 1130, 584, 0, 0, 1077, 6]\n",
      "this <|unk|> <|unk|> <|endoftext|> is!! was--\n",
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  198, 11274,  5891,  1576],\n",
      "        [  438,   568,   340,   373],\n",
      "        [  645,  1049,  5975,   284],\n",
      "        [  502,   284,  3285,   326]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   198],\n",
      "        [11274,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "torch.Size([8, 4, 256])\n",
      "torch.Size([4, 256])\n",
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "# Load GPT model\n",
    "%run gpt-model.ipynb\n",
    "%run data-processing.ipynb\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1109fc1f",
   "metadata": {},
   "source": [
    "Config definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ba22ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,  # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,  # Dropout rate\n",
    "    \"qkv_bias\": True,  # Query-key-value bias\n",
    "}\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\n",
    "        \"emb_dim\": 768,\n",
    "        \"n_layers\": 12,\n",
    "        \"n_heads\": 12,\n",
    "        \"file_name\": \"gpt2-small-124M.pth\",\n",
    "    },\n",
    "    \"gpt2-medium (355M)\": {\n",
    "        \"emb_dim\": 1024,\n",
    "        \"n_layers\": 24,\n",
    "        \"n_heads\": 16,\n",
    "        \"file_name\": \"gpt2-medium-355M.pth\",\n",
    "    },\n",
    "    \"gpt2-large (774M)\": {\n",
    "        \"emb_dim\": 1280,\n",
    "        \"n_layers\": 36,\n",
    "        \"n_heads\": 20,\n",
    "        \"file_name\": \"gpt2-large-774M.pth\",\n",
    "    },\n",
    "    \"gpt2-xl (1558M)\": {\n",
    "        \"emb_dim\": 1600,\n",
    "        \"n_layers\": 48,\n",
    "        \"n_heads\": 25,\n",
    "        \"file_name\": \"gpt2-xl-1558M.pth\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c787279",
   "metadata": {},
   "source": [
    "Loading the model.\n",
    "\n",
    "We load Medium-355M instead of the Small-124M as the smallest models don't have enough capacity to learn to be instruction-tuned properly.\n",
    "\n",
    "TODO: Test this hypothesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89d26a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt2-medium (355M)\"\n",
    "file_name = model_configs[model_name][\"file_name\"]\n",
    "BASE_CONFIG.update(model_configs[model_name])\n",
    "\n",
    "url = f\"https://huggingface.co/rasbt/gpt2-from-scratch-pytorch/resolve/main/{file_name}\"\n",
    "\n",
    "if not os.path.exists(file_name):\n",
    "    urllib.request.urlretrieve(url, file_name)\n",
    "    print(f\"Downloaded to {file_name}\")\n",
    "\n",
    "gpt = GPTModel(BASE_CONFIG)\n",
    "gpt.load_state_dict(torch.load(file_name, weights_only=True))\n",
    "gpt.eval()\n",
    "\n",
    "device = torch.device(get_device())\n",
    "gpt.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a4816a",
   "metadata": {},
   "source": [
    "##### Testing the Model before tuning it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "01308c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={\"<|endoftext|>\"})\n",
    "    return torch.tensor(encoded).unsqueeze(0)\n",
    "\n",
    "\n",
    "def token_ids_to_text(tokens, tokenizer):\n",
    "    formatted = tokens.squeeze(0).tolist()\n",
    "    return tokenizer.decode(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "429da02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Convert the active sentence to passive: 'The chef cooks the meal every day.'\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "input_text = format_input(val_data[0])\n",
    "print(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbec8bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = generateText(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(input_text, tokenizer).to(\n",
    "        device\n",
    "    ),  # Ensure input is on the correct device\n",
    "    max_new_tokens=35,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    eos_id=50256,\n",
    ")\n",
    "generated_text = token_ids_to_text(token_ids, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "12ba8eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "\n",
      "The chef cooks the meal every day.\n",
      "\n",
      "### Instruction:\n",
      "\n",
      "Convert the active sentence to passive: 'The chef cooks the\n"
     ]
    }
   ],
   "source": [
    "response_text = generated_text[len(input_text) :].strip()\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e4bdf6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a given batch, compute the cross entropy.\n",
    "def calc_loss_batch(\n",
    "    input_batch: torch.Tensor,\n",
    "    target_batch: torch.Tensor,\n",
    "    model: torch.nn.Module,\n",
    "    device,\n",
    "):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    # Run model.\n",
    "    logits = model(input_batch)\n",
    "    # Compute cross-entropy loss.\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Calculate the loss for a given data_loader.\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=torch.inf):\n",
    "    total_loss = 0.0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "    else:\n",
    "        num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "    # Iterate through batches and compute sum loss.\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i > num_batches:\n",
    "            break\n",
    "        loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "        total_loss += loss.item()\n",
    "    # Return avg. loss.\n",
    "    return total_loss / num_batches\n",
    "\n",
    "\n",
    "# Evaluate the model on the train and validation loaders. Runs only on the `eval_iter` number of batches.\n",
    "# Returns the train and validation losses.\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "    model.train()\n",
    "    return train_loss, val_loss\n",
    "\n",
    "\n",
    "# Generates text.\n",
    "def generate_and_print_sample(\n",
    "    model,\n",
    "    tokenizer,\n",
    "    device,\n",
    "    start_context,\n",
    "    temperature: int = 0.0,\n",
    "    top_k=None,\n",
    "    eos_id=None,\n",
    "):\n",
    "    model.eval()\n",
    "    context_size = model.pos_emb.weight.shape[0]\n",
    "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generateText(\n",
    "            model=model,\n",
    "            idx=encoded,\n",
    "            max_new_tokens=50,\n",
    "            context_size=context_size,\n",
    "            temperature=temperature,\n",
    "            top_k=top_k,\n",
    "        )\n",
    "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()\n",
    "\n",
    "\n",
    "# Trains the model.\n",
    "# Returns the train, validation losses, and a list of all the tokens seen during training.\n",
    "def train_model_simple(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs,\n",
    "    eval_freq,\n",
    "    eval_iter,\n",
    "    start_context,\n",
    "    tokenizer,\n",
    "):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    def print_evals():\n",
    "        train_loss, val_loss = evaluate_model(\n",
    "            model, train_loader, val_loader, device, eval_iter\n",
    "        )\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        track_tokens_seen.append(tokens_seen)\n",
    "        print(\n",
    "            f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "            f\"Train loss {train_loss:.3f}, \"\n",
    "            f\"Val loss {val_loss:.3f}\"\n",
    "        )\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Print evals.\n",
    "            if global_step % eval_freq == 0:\n",
    "                print_evals()\n",
    "\n",
    "        generate_and_print_sample(model, tokenizer, device, start_context)\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1a718246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 4.619566631317139\n",
      "Validation loss: 4.510749673843383\n"
     ]
    }
   ],
   "source": [
    "gpt.to(device)\n",
    "torch.manual_seed(123)\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, gpt, device, num_batches=5)\n",
    "    val_loss = calc_loss_loader(val_loader, gpt, device, num_batches=5)\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122a6f20",
   "metadata": {},
   "source": [
    "### Instruction Fine Tuning the LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efab6caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 3.168, Val loss 3.156\n",
      "Ep 1 (Step 000005): Train loss 1.309, Val loss 1.337\n",
      "Ep 1 (Step 000010): Train loss 1.081, Val loss 1.127\n",
      "Ep 1 (Step 000015): Train loss 0.986, Val loss 1.061\n",
      "Ep 1 (Step 000020): Train loss 0.928, Val loss 1.039\n",
      "Ep 1 (Step 000025): Train loss 0.902, Val loss 1.031\n",
      "Ep 1 (Step 000030): Train loss 0.895, Val loss 0.956\n",
      "Ep 1 (Step 000035): Train loss 0.896, Val loss 0.959\n",
      "Ep 1 (Step 000040): Train loss 0.771, Val loss 0.933\n",
      "Ep 1 (Step 000045): Train loss 0.921, Val loss 0.900\n",
      "Ep 1 (Step 000050): Train loss 0.817, Val loss 0.899\n",
      "Ep 1 (Step 000055): Train loss 0.699, Val loss 0.898\n",
      "Ep 1 (Step 000060): Train loss 0.776, Val loss 0.883\n",
      "Ep 1 (Step 000065): Train loss 0.816, Val loss 0.872\n",
      "Ep 1 (Step 000070): Train loss 0.674, Val loss 0.856\n",
      "Ep 1 (Step 000075): Train loss 0.704, Val loss 0.880\n",
      "Ep 1 (Step 000080): Train loss 0.795, Val loss 0.869\n",
      "Ep 1 (Step 000085): Train loss 0.684, Val loss 0.853\n",
      "Ep 1 (Step 000090): Train loss 0.627, Val loss 0.824\n",
      "Ep 1 (Step 000095): Train loss 0.741, Val loss 0.838\n",
      "Ep 1 (Step 000100): Train loss 0.673, Val loss 0.808\n",
      "Ep 1 (Step 000105): Train loss 0.523, Val loss 0.765\n",
      "Ep 1 (Step 000110): Train loss 0.610, Val loss 0.800\n",
      "Ep 1 (Step 000115): Train loss 0.542, Val loss 0.774\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The meal is prepared every day by the chef.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive:\n",
      "Ep 2 (Step 000120): Train loss 0.583, Val loss 0.784\n",
      "Ep 2 (Step 000125): Train loss 0.541, Val loss 0.808\n",
      "Ep 2 (Step 000130): Train loss 0.552, Val loss 0.771\n",
      "Ep 2 (Step 000135): Train loss 0.566, Val loss 0.776\n",
      "Ep 2 (Step 000140): Train loss 0.514, Val loss 0.809\n",
      "Ep 2 (Step 000145): Train loss 0.533, Val loss 0.834\n",
      "Ep 2 (Step 000150): Train loss 0.459, Val loss 0.816\n",
      "Ep 2 (Step 000155): Train loss 0.520, Val loss 0.759\n",
      "Ep 2 (Step 000160): Train loss 0.555, Val loss 0.806\n",
      "Ep 2 (Step 000165): Train loss 0.448, Val loss 0.809\n",
      "Ep 2 (Step 000170): Train loss 0.503, Val loss 0.787\n",
      "Ep 2 (Step 000175): Train loss 0.449, Val loss 0.770\n",
      "Ep 2 (Step 000180): Train loss 0.454, Val loss 0.818\n",
      "Ep 2 (Step 000185): Train loss 0.466, Val loss 0.785\n",
      "Ep 2 (Step 000190): Train loss 0.452, Val loss 0.804\n",
      "Ep 2 (Step 000195): Train loss 0.469, Val loss 0.759\n",
      "Ep 2 (Step 000200): Train loss 0.411, Val loss 0.754\n",
      "Ep 2 (Step 000205): Train loss 0.420, Val loss 0.734\n",
      "Ep 2 (Step 000210): Train loss 0.412, Val loss 0.728\n",
      "Ep 2 (Step 000215): Train loss 0.387, Val loss 0.766\n",
      "Ep 2 (Step 000220): Train loss 0.377, Val loss 0.754\n",
      "Ep 2 (Step 000225): Train loss 0.377, Val loss 0.729\n",
      "Ep 2 (Step 000230): Train loss 0.417, Val loss 0.764\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Convert the active sentence to passive: 'The chef cooks the meal every day.'  ### Response: The chef cooks the meal every day.<|endoftext|>The following is an instruction that describes a task. Write a response that appropriately completes the request.  ### Instruction: Rewrite the sentence using a simile. \n",
      "Training completed in 3.85 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(gpt.parameters(), lr=0.00005, weight_decay=0.1)\n",
    "num_epochs = 2\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    gpt,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    device,\n",
    "    num_epochs=num_epochs,\n",
    "    eval_freq=5,\n",
    "    eval_iter=5,\n",
    "    start_context=format_input(val_data[0]),\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471a7202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "def _to_list(x):\n",
    "    if torch.is_tensor(x):\n",
    "        # avoids .numpy() so no NumPy dependency\n",
    "        return x.detach().cpu().tolist()\n",
    "    # handle lists/tuples already\n",
    "    return x\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37debd1a",
   "metadata": {},
   "source": [
    "##### TODO: Exercise 7.3 Fine-tuning on the original Alpaca dataset\n",
    "The Alpaca dataset, by researchers at Stanford, is one of the earliest and most pop-\n",
    "ular openly shared instruction datasets, consisting of 52,002 entries. As an alterna-\n",
    "tive to the instruction-data.json file we use here, consider fine-tuning an LLM on\n",
    "this dataset. The dataset is available at https://mng.bz/NBnE.\n",
    "This dataset contains 52,002 entries, which is approximately 50 times more than\n",
    "those we used here, and most entries are longer. Thus, I highly recommend using a\n",
    "GPU to conduct the training, which will accelerate the fine-tuning process. If you\n",
    "encounter out-of-memory errors, consider reducing the batch_size from 8 to 4, 2,\n",
    "or even 1. Lowering the allowed_max_length from 1,024 to 512 or 256 can also\n",
    "help manage memory problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329a8485",
   "metadata": {},
   "source": [
    "#### Extracting and saving responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f14fab65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Rewrite the sentence using a simile.\n",
      "\n",
      "### Input:\n",
      "The car is very fast.\n",
      "\n",
      "Correct response:\n",
      ">> The car is as fast as lightning.\n",
      "\n",
      "Model response:\n",
      ">> The car is as fast as a cheetah.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What type of cloud is typically associated with thunderstorms?\n",
      "\n",
      "Correct response:\n",
      ">> The type of cloud typically associated with thunderstorms is cumulonimbus.\n",
      "\n",
      "Model response:\n",
      ">> A thunderstorm is a type of storm that typically produces a strong wind and/or rain.\n",
      "-------------------------------------\n",
      "Below is an instruction that describes a task. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Name the author of 'Pride and Prejudice'.\n",
      "\n",
      "Correct response:\n",
      ">> Jane Austen.\n",
      "\n",
      "Model response:\n",
      ">> The author of 'Pride and Prejudice' is Jane Austen.\n",
      "-------------------------------------\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "for entry in test_data[:3]:\n",
    "    input_text = format_input(entry)\n",
    "    token_ids = generateText(\n",
    "        model=gpt,\n",
    "        idx=text_to_token_ids(input_text, tokenizer).to(device),\n",
    "        max_new_tokens=256,\n",
    "        context_size=BASE_CONFIG[\"context_length\"],\n",
    "        eos_id=50256,\n",
    "    )\n",
    "    generated_text = token_ids_to_text(token_ids, tokenizer)\n",
    "    response_text = (\n",
    "        generated_text[len(input_text) :].replace(\"### Response:\", \"\").strip()\n",
    "    )\n",
    "    print(input_text)\n",
    "    print(f\"\\nCorrect response:\\n>> {entry['output']}\")\n",
    "    print(f\"\\nModel response:\\n>> {response_text.strip()}\")\n",
    "    print(\"-------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
