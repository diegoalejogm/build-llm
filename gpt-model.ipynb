{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0398ef5",
   "metadata": {},
   "source": [
    "# GPT Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8000ece1",
   "metadata": {},
   "source": [
    "In this notebook we will implement the GPT-2 model. \n",
    "\n",
    "To start, we implement at dummy class that shows the architecture of the neural network. \n",
    "\n",
    "Then, we implement the layers we mocked in the dummy GPT model.\n",
    "\n",
    "Finally, we put everything back together with a few additions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "85427293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637592a8",
   "metadata": {},
   "source": [
    "## Dummy GPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3089cf",
   "metadata": {},
   "source": [
    "We implement a dummy GPT class below, with the following architecture:\n",
    "\n",
    "\n",
    "Architecture:\n",
    "```\n",
    "DummyGPT(\n",
    "  (dropout): Dropout(p=0.1, inplace=False)\n",
    "  (tokenEmbed): Embedding(50257, 768)\n",
    "  (posEmbed): Embedding(1024, 768)\n",
    "  (normLayer): DummyLayerNorm()\n",
    "  (trfBlocks): Sequential(\n",
    "    (0): DummyTransformer()\n",
    "    (1): DummyTransformer()\n",
    "    (2): DummyTransformer()\n",
    "    (3): DummyTransformer()\n",
    "    (4): DummyTransformer()\n",
    "    (5): DummyTransformer()\n",
    "    (6): DummyTransformer()\n",
    "    (7): DummyTransformer()\n",
    "    (8): DummyTransformer()\n",
    "    (9): DummyTransformer()\n",
    "    (10): DummyTransformer()\n",
    "    (11): DummyTransformer()\n",
    "  )\n",
    "  (outLayer): Linear(in_features=768, out_features=50257, bias=False)\n",
    ")\n",
    "```\n",
    "\n",
    "The model will be initialized using a configuration dictionary that will contain the number of layers and other model parameters. \n",
    "\n",
    "We use the parameters from GPT-2 for reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7e2302c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"vocabSize\": 50257, # Number of tokens in vocabulary.\n",
    "    \"contextLength\": 1024, # Max. number of tokens the LLM sees per run.\n",
    "    \"embedDim\": 768, # Size of the internal. embeddings used in the LLM attention mechanism.\n",
    "    \"nLayers\" : 12, # Number of transformer layers.\n",
    "    \"dropRate\": 0.1, # Feature dropout rate.\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "44577105",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyLayerNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "class DummyTransformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dce4c5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DummyGPT(nn.Module):\n",
    "    def __init__(self, cfg):\n",
    "        super().__init__()\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(cfg[\"dropRate\"])\n",
    "        # Token embedding\n",
    "        self.tokenEmbed = nn.Embedding(cfg[\"vocabSize\"], cfg[\"embedDim\"])\n",
    "        # Positional embedding\n",
    "        self.posEmbed = nn.Embedding(cfg[\"contextLength\"], cfg[\"embedDim\"])\n",
    "        # Normalization\n",
    "        self.normLayer = DummyLayerNorm()\n",
    "        # Transformer Blocks\n",
    "        self.trfBlocks = nn.Sequential(*[\n",
    "            DummyTransformer() for _ in range(cfg[\"nLayers\"])\n",
    "        ])\n",
    "        # Linear projection.\n",
    "        self.outLayer = nn.Linear(cfg[\"embedDim\"], cfg[\"vocabSize\"], bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, seqLen = x.shape\n",
    "        tokEmbeds = self.tokenEmbed(x)\n",
    "        posEmbeds = self.posEmbed(torch.arange(seqLen, device=x.device))\n",
    "        x = tokEmbeds + posEmbeds\n",
    "        x = self.dropout(x)\n",
    "        x = self.normLayer(x)\n",
    "        for l in self.trfBlocks:\n",
    "            x = l(x)\n",
    "        return self.outLayer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b6e7bb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DummyGPT(\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (tokenEmbed): Embedding(50257, 768)\n",
       "  (posEmbed): Embedding(1024, 768)\n",
       "  (normLayer): DummyLayerNorm()\n",
       "  (trfBlocks): Sequential(\n",
       "    (0): DummyTransformer()\n",
       "    (1): DummyTransformer()\n",
       "    (2): DummyTransformer()\n",
       "    (3): DummyTransformer()\n",
       "    (4): DummyTransformer()\n",
       "    (5): DummyTransformer()\n",
       "    (6): DummyTransformer()\n",
       "    (7): DummyTransformer()\n",
       "    (8): DummyTransformer()\n",
       "    (9): DummyTransformer()\n",
       "    (10): DummyTransformer()\n",
       "    (11): DummyTransformer()\n",
       "  )\n",
       "  (outLayer): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize model.\n",
    "dummyGpt = DummyGPT(cfg)\n",
    "dummyGpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b820bd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a batch to be used for testing purposes\n",
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "batch = []\n",
    "txt1 = \"Every effort moves you\"\n",
    "txt2 = \"Every day holds a\"\n",
    "batch.append(torch.tensor(tokenizer.encode(txt1)))\n",
    "batch.append(torch.tensor(tokenizer.encode(txt2)))\n",
    "batch = torch.stack(batch, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f0a67fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      " fixedndum caves alert\n",
      "religious positionsScreenshot Fac\n"
     ]
    }
   ],
   "source": [
    "# Initialize model and run model on batch.\n",
    "# Model isn't trained and all ouputs are gibberish.\n",
    "\n",
    "logits = dummyGpt(batch)  # shape: [batch, seqLen, vocabSize]\n",
    "pred_ids = logits.argmax(dim=-1)  # shape: [batch, seqLen]\n",
    "print(batch)\n",
    "for i in range(pred_ids.shape[0]):\n",
    "    print(tokenizer.decode(pred_ids[i].tolist()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f6b6a2",
   "metadata": {},
   "source": [
    "# Layer Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53648fa0",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
