{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1b33deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import zipfile\n",
    "import os\n",
    "from pathlib import Path\n",
    "url = \"https://archive.ics.uci.edu/static/public/228/sms+spam+collection.zip\"\n",
    "zip_path = \"sms_spam_collection.zip\"\n",
    "extracted_path = \"sms_spam_collection\"\n",
    "data_file_path = Path(extracted_path) / \"SMSSpamCollection.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1816617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sms_spam_collection/SMSSpamCollection.tsv already exists. Skipping download and extraction.\n"
     ]
    }
   ],
   "source": [
    "def download_and_unzip_spam_data(\n",
    "    url, zip_path, extracted_path, data_file_path):\n",
    "    if data_file_path.exists():\n",
    "        print(f\"{data_file_path} already exists. Skipping download \"\n",
    "            \"and extraction.\"\n",
    "        )\n",
    "        return\n",
    "    with urllib.request.urlopen(url) as response:\n",
    "        with open(zip_path, \"wb\") as out_file:\n",
    "            out_file.write(response.read())\n",
    "    with zipfile.ZipFile(zip_path, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(extracted_path)\n",
    "\n",
    "    original_file_path = Path(extracted_path) / \"SMSSpamCollection\"\n",
    "    os.rename(original_file_path, data_file_path)\n",
    "    print(f\"File downloaded and saved as {data_file_path}\")\n",
    "\n",
    "download_and_unzip_spam_data(url, zip_path, extracted_path, data_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e11bb8f7",
   "metadata": {},
   "source": [
    "#### Load into a Pandas DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea640ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(data_file_path, sep=\"\\t\", header=None, names=[\"Label\", \"Text\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e50e88e",
   "metadata": {},
   "source": [
    "#### Examine value distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da49fc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fd3205",
   "metadata": {},
   "source": [
    "There is a class inbalance. For ease, we will keep a 50:50 class-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e72f167b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "spam    747\n",
      "ham     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "    spam_df = df[df[\"Label\"] == \"spam\"]\n",
    "    ham_df = df[df[\"Label\"] == \"ham\"].sample(n=len(spam_df), random_state=123)\n",
    "    balanced_df = pd.concat([spam_df, ham_df])\n",
    "    return balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2144024",
   "metadata": {},
   "source": [
    "Map labels into integers {1, 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff40a7f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>SIX chances to win CASH! From 100 to 20,000 po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4707</th>\n",
       "      <td>0</td>\n",
       "      <td>Wow so healthy. Old airport rd lor. Cant thk o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3293</th>\n",
       "      <td>0</td>\n",
       "      <td>Dear good morning how you feeling dear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>0</td>\n",
       "      <td>Dont put your phone on silent mode ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4079</th>\n",
       "      <td>0</td>\n",
       "      <td>Gam gone after outstanding innings.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4468</th>\n",
       "      <td>0</td>\n",
       "      <td>She said,'' do u mind if I go into the bedroom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1494 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Label                                               Text\n",
       "2         1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "5         1  FreeMsg Hey there darling it's been 3 week's n...\n",
       "8         1  WINNER!! As a valued network customer you have...\n",
       "9         1  Had your mobile 11 months or more? U R entitle...\n",
       "11        1  SIX chances to win CASH! From 100 to 20,000 po...\n",
       "...     ...                                                ...\n",
       "4707      0  Wow so healthy. Old airport rd lor. Cant thk o...\n",
       "3293      0             Dear good morning how you feeling dear\n",
       "1278      0              Dont put your phone on silent mode ok\n",
       "4079      0                Gam gone after outstanding innings.\n",
       "4468      0  She said,'' do u mind if I go into the bedroom...\n",
       "\n",
       "[1494 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({\"ham\": 0, \"spam\": 1})\n",
    "balanced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013a3509",
   "metadata": {},
   "source": [
    "##### Create random split for training, validation, test (70%, 10%, 20%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db91d2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1045\n",
      "Validation size: 150\n",
      "Test size: 299\n"
     ]
    }
   ],
   "source": [
    "def random_split(df, train_frac=0.7, val_frac=0.1, random_state=123):\n",
    "    # Shuffle the DataFrame.\n",
    "    df = df.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    train_end = int(len(df) * train_frac)\n",
    "    val_end = int(len(df) * (train_frac + val_frac))\n",
    "    df_train = df[:train_end]\n",
    "    df_val = df[train_end:val_end]\n",
    "    df_test = df[val_end:]\n",
    "    return df_train, df_val, df_test\n",
    "\n",
    "df_train, df_val, df_test = random_split(balanced_df)\n",
    "print(f\"Train size: {len(df_train)}\")\n",
    "print(f\"Validation size: {len(df_val)}\")\n",
    "print(f\"Test size: {len(df_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57eecbe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV files.\n",
    "df_train.to_csv(\"train.csv\", index=None)\n",
    "df_val.to_csv(\"validation.csv\", index=None)\n",
    "df_test.to_csv(\"test.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2039d0e4",
   "metadata": {},
   "source": [
    "### Create Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64b8055a",
   "metadata": {},
   "source": [
    "We now need to create a dataloader to ingest the data into the LLM. \n",
    "\n",
    "Note that the text messages may have different sizes, and thus we will pad all messages to have the same length in a given batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2bb668b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "    def __init__(self, csv_file, tokenizer, max_length=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.pad_token_id = tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"})[0]\n",
    "\n",
    "        # Encode all texts in the dataset.\n",
    "        self.encoded_texts = [tokenizer.encode(text) for text in self.data[\"Text\"]]\n",
    "        if max_length is None:\n",
    "            self.max_length = self._longest_encoded_length()\n",
    "        else:\n",
    "            self.max_length = max_length\n",
    "            # Truncate texts that are longer than max_length.\n",
    "            self.encoded_texts = [enc[:max_length] for enc in self.encoded_texts]\n",
    "        \n",
    "        # Pad all encoded texts to max_length.\n",
    "        self.encoded_texts = [\n",
    "            enc + [self.pad_token_id] * (self.max_length - len(enc)) for enc in self.encoded_texts\n",
    "        ]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = torch.tensor(self.encoded_texts[idx], dtype=torch.long)\n",
    "        label = torch.tensor(self.data.iloc[idx][\"Label\"], dtype=torch.long)\n",
    "        return text, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def _longest_encoded_length(self):\n",
    "        return max(len(enc) for enc in self.encoded_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bb875b",
   "metadata": {},
   "source": [
    "##### Load Train, Validation and Test sets into the dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00dc50b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: Number of tokens in the longest sequence: 120\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "train_dataset = SpamDataset(\"train.csv\", max_length=None, tokenizer=tokenizer)\n",
    "print( \"Train: Number of tokens in the longest sequence:\", train_dataset.max_length)\n",
    "\n",
    "val_dataset = SpamDataset(\"validation.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)\n",
    "test_dataset = SpamDataset(\"test.csv\", max_length=train_dataset.max_length, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac2c878",
   "metadata": {},
   "source": [
    "##### TODO: Exercise 6.1 Increasing the context length\n",
    "Pad the inputs to the maximum number of tokens the model supports and observe\n",
    "how it affects the predictive performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbbedd6",
   "metadata": {},
   "source": [
    "### Creating Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45c49783",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 8\n",
    "num_workers = 0\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset, \n",
    "    batch_size=batch_size, \n",
    "    num_workers=num_workers, \n",
    "    shuffle=True, \n",
    "    drop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset, \n",
    "    batch_size=batch_size, \n",
    "    num_workers=num_workers, \n",
    "    shuffle=False, \n",
    "    drop_last=False\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset, \n",
    "    batch_size=batch_size, \n",
    "    num_workers=num_workers, \n",
    "    shuffle=False, \n",
    "    drop_last=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8628f09",
   "metadata": {},
   "source": [
    "To get an idea of the batch shapes, let's print them down below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c56e3f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch dimensions: torch.Size([8, 120])\n",
      "Label batch dimensions: torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "for input_batch, target_batch in train_loader:\n",
    "    break\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Label batch dimensions:\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad8c8c9",
   "metadata": {},
   "source": [
    "To get an idea of the dataset size, let's print it down below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61aac7e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 batches in the training DataLoader\n",
      "19 batches in the validation DataLoader\n",
      "38 batches in the test DataLoader\n"
     ]
    }
   ],
   "source": [
    "print(len(train_loader), \"batches in the training DataLoader\")\n",
    "print(len(val_loader), \"batches in the validation DataLoader\")\n",
    "print(len(test_loader), \"batches in the test DataLoader\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f8b80a",
   "metadata": {},
   "source": [
    "#### Load GPT2 Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8929f732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      " Jiang exclude intensimet\n",
      " B LeavingACC Deng\n",
      "Mean:\n",
      "  tensor([-0.3596, -0.2606])\n",
      "Variance :\n",
      "  tensor([0.2015, 0.2673])\n",
      "Norm. Mean:\n",
      "  tensor([    -0.0000,      0.0000], grad_fn=<MeanBackward1>)\n",
      "Norm. Variance :\n",
      "  tensor([1.0000, 1.0000], grad_fn=<VarBackward0>)\n",
      "tensor([[0.2685, 0.7413],\n",
      "        [0.2738, 0.7564],\n",
      "        [0.2668, 0.7366],\n",
      "        [0.2618, 0.7218],\n",
      "        [0.2712, 0.7495]], grad_fn=<MmBackward0>)\n",
      "tensor([[-0.4927, -0.0791],\n",
      "        [-0.4938, -0.0806],\n",
      "        [-0.4924, -0.0851],\n",
      "        [-0.4923, -0.0819],\n",
      "        [-0.4928, -0.0853]], grad_fn=<MmBackward0>)\n",
      "Self Attention V2 output: \n",
      " tensor([[-0.4927, -0.0791],\n",
      "        [-0.4938, -0.0806],\n",
      "        [-0.4924, -0.0851],\n",
      "        [-0.4923, -0.0819],\n",
      "        [-0.4928, -0.0853]], grad_fn=<MmBackward0>)\n",
      "Self Attention V1 output: \n",
      " tensor([[-0.4927, -0.0791],\n",
      "        [-0.4938, -0.0806],\n",
      "        [-0.4924, -0.0851],\n",
      "        [-0.4923, -0.0819],\n",
      "        [-0.4928, -0.0853]], grad_fn=<MmBackward0>)\n",
      "batch.shape: torch.Size([2, 5, 3])\n",
      "contextVecs.shape: torch.Size([2, 5, 2])\n",
      "batch.shape: torch.Size([2, 5, 3])\n",
      "contextVecs.shape: torch.Size([2, 5, 4])\n",
      "batch.shape: torch.Size([2, 5, 3])\n",
      "contextVecs.shape: torch.Size([2, 5, 2])\n",
      "batch.shape: torch.Size([2, 1024, 768])\n",
      "contextVecs.shape: torch.Size([2, 1024, 768])\n",
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n",
      "Output: tensor([[15496,    11,   314,   716, 24111, 43446, 11311, 42014, 15660, 43819]])\n",
      "Output length: 10\n",
      "Hello, I amFrench rebirth chocolate horny incentiveliterally\n",
      "year 1122\n",
      "years 1123\n",
      "yellow 1124\n",
      "yet 1125\n",
      "you 1126\n",
      "younger 1127\n",
      "your 1128\n",
      "yourself 1129\n",
      "<|endoftext|> 1130\n",
      "<|unk|> 1131\n",
      "[999, 1131, 1131, 1130, 584, 0, 0, 1077, 6]\n",
      "this <|unk|> <|unk|> <|endoftext|> is!! was--\n",
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  198, 11274,  5891,  1576],\n",
      "        [  438,   568,   340,   373],\n",
      "        [  645,  1049,  5975,   284],\n",
      "        [  502,   284,  3285,   326]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   198],\n",
      "        [11274,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "torch.Size([8, 4, 256])\n",
      "torch.Size([4, 256])\n",
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "# Load GPT model\n",
    "%run gpt-model.ipynb\n",
    "%run data-processing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42e981b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12, \"file_name\": \"gpt2-small-124M.pth\"},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16, \"file_name\": \"gpt2-medium-355M.pth\"},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20, \"file_name\": \"gpt2-large-774M.pth\"},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25, \"file_name\": \"gpt2-xl-1558M.pth\"},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad7324a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,\n",
    "    \"context_length\": 1024,\n",
    "    \"drop_rate\": 0.0,\n",
    "    \"qkv_bias\": True,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba32020f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"gpt2-small (124M)\"\n",
    "file_name = model_configs[model_name][\"file_name\"]\n",
    "BASE_CONFIG.update(model_configs[model_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b360ab4b",
   "metadata": {},
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fd32fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_token_ids(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    return torch.tensor(encoded).unsqueeze(0)\n",
    "\n",
    "def token_ids_to_text(tokens, tokenizer):\n",
    "    formatted = tokens.squeeze(0).tolist()\n",
    "    return tokenizer.decode(formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d83055a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (ff): FeedForwardModule(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (ff): FeedForwardModule(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (ff): FeedForwardModule(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (ff): FeedForwardModule(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (ff): FeedForwardModule(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (ff): FeedForwardModule(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (ff): FeedForwardModule(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (ff): FeedForwardModule(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (ff): FeedForwardModule(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (ff): FeedForwardModule(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (ff): FeedForwardModule(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.0, inplace=False)\n",
       "      (ff): FeedForwardModule(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = f\"https://huggingface.co/rasbt/gpt2-from-scratch-pytorch/resolve/main/{file_name}\"\n",
    "\n",
    "if not os.path.exists(file_name):\n",
    "    urllib.request.urlretrieve(url, file_name)\n",
    "    print(f\"Downloaded to {file_name}\")\n",
    "\n",
    "gpt = GPTModel(BASE_CONFIG)\n",
    "gpt.load_state_dict(torch.load(file_name, weights_only=True))\n",
    "gpt.eval()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "gpt.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2a0009e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output text:\n",
      " Every effort moves you toward an equal share for each vote plus half. Inequality is often not an accurate representation of human worth; to know the\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "token_ids = generateText(\n",
    "    model=gpt,\n",
    "    idx=text_to_token_ids(\"Every effort moves you\", tokenizer).to(device),\n",
    "    max_new_tokens=25,\n",
    "    context_size=BASE_CONFIG[\"context_length\"],\n",
    "    top_k=50,\n",
    "    temperature=1.5\n",
    ")\n",
    "\n",
    "print(\"Output text:\\n\", token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6243e31",
   "metadata": {},
   "source": [
    "Let's test whether the model is good at classifying spam already, before doing any fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11958b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no': 'You are a winner you have been specially selected to receive $1000 cash or a $2000 award.' clans Chester seasonal borrowed elevate tou Sorazek Hats Arkham subreddit manipulated Belle famously appreciation declaresildo lich PowerShell expireucked SHnesday\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Is the following text 'spam'? Answer with 'yes' or 'no':\"\n",
    "    \" 'You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.'\"\n",
    ")\n",
    "token_ids = generateText(\n",
    "    model=model,\n",
    "    idx=text_to_token_ids(text_2, tokenizer),\n",
    "    max_new_tokens=23,\n",
    "    context_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2624b114",
   "metadata": {},
   "source": [
    "As you can see, the model is not able to classify the text into spam or not spam, it just autocompletes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ed9a51",
   "metadata": {},
   "source": [
    "### Adding a Classification Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cca81a",
   "metadata": {},
   "source": [
    "Let's first display the structure of the model.\n",
    "As expected, the last layer of the model has an output size of ~50k, equivalent to the size of the model vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c73114dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPTModel(\n",
      "  (tok_emb): Embedding(50257, 768)\n",
      "  (pos_emb): Embedding(1024, 768)\n",
      "  (trf_blocks): Sequential(\n",
      "    (0): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (ff): FeedForwardModule(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (1): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (ff): FeedForwardModule(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (2): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (ff): FeedForwardModule(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (3): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (ff): FeedForwardModule(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (4): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (ff): FeedForwardModule(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (5): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (ff): FeedForwardModule(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (6): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (ff): FeedForwardModule(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (7): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (ff): FeedForwardModule(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (8): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (ff): FeedForwardModule(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (9): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (ff): FeedForwardModule(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (10): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (ff): FeedForwardModule(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (11): TransformerBlock(\n",
      "      (norm1): LayerNorm()\n",
      "      (norm2): LayerNorm()\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "      (ff): FeedForwardModule(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU()\n",
      "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "        )\n",
      "      )\n",
      "      (att): MultiHeadAttention(\n",
      "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (final_norm): LayerNorm()\n",
      "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(gpt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd02844",
   "metadata": {},
   "source": [
    "##### Freeze all weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fb315bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc596dd",
   "metadata": {},
   "source": [
    "##### Replace classification layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2752cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "num_classes = 2\n",
    "# This new layer has requires_grad=True by default.\n",
    "gpt.out_head = torch.nn.Linear(BASE_CONFIG[\"emb_dim\"], num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bab653",
   "metadata": {},
   "source": [
    "##### Unfreeze last transformer block and final layer norm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eb07c9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in gpt.trf_blocks[-1].parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "for param in gpt.final_norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64efb120",
   "metadata": {},
   "source": [
    "##### Test the new model output shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc431ce",
   "metadata": {},
   "source": [
    "Let's first create the input dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8d5f5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs dimensions: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs dimensions:\", inputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702cae4f",
   "metadata": {},
   "source": [
    "The last output dimension is now `2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "56f5332a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs:\n",
      " tensor([[[-1.5854,  0.9904],\n",
      "         [-3.7234,  7.4548],\n",
      "         [-2.2660,  6.6049],\n",
      "         [-3.5983,  3.9901]]])\n",
      "Outputs dimensions: torch.Size([1, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = gpt(inputs)\n",
    "    print(\"Outputs:\\n\", outputs)\n",
    "    print(\"Outputs dimensions:\", outputs.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6194714b",
   "metadata": {},
   "source": [
    "The first dimension `1` is the batch size, `4` is the token dimension, `2` is the output dimension.\n",
    "\n",
    "We use the output of the latest token as it is the prediction of the model when it uses all of the tokens as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f34b21c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983,  3.9901]])\n"
     ]
    }
   ],
   "source": [
    "print(\"Last output token:\", outputs[:, -1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ae4515",
   "metadata": {},
   "source": [
    "In order to obtain the class label, we take the argmax. \n",
    "\n",
    "There is no need to apply the softmax as we don't need to know the probability scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0a107171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2baf00f",
   "metadata": {},
   "source": [
    "##### TODO: Exercise 6.3 Fine-tuning the first vs. last token\n",
    "Try fine-tuning the first output token. Notice the changes in predictive performance\n",
    "compared to fine-tuning the last output token."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f162372d",
   "metadata": {},
   "source": [
    "##### Create function to measure loader's accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e45efffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_accuracy_loader(data_loader, model, device, num_batches=None): \n",
    "    correct_predictions, num_examples = 0, 0\n",
    "\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i >= num_batches: break\n",
    "\n",
    "        input_batch = input_batch.to(device)\n",
    "        target_batch = target_batch.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            logits = model(input_batch)[ :, -1, :]\n",
    "        predicted_labels = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "        num_examples += predicted_labels.shape[0]\n",
    "        correct_predictions += (predicted_labels == target_batch).sum().item()\n",
    "\n",
    "    return correct_predictions / num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f884f86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy : 25.00%\n",
      "Val. Accuracy : 50.00%\n",
      "Test Accuracy : 37.50%\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"mps\"\n",
    "\n",
    "train_accuracy = calc_accuracy_loader(train_loader, gpt, device, 1)\n",
    "val_accuracy =  calc_accuracy_loader(val_loader, gpt, device, 1)\n",
    "test_accuracy =  calc_accuracy_loader(test_loader, gpt, device, 1)\n",
    "\n",
    "print (f\"Training Accuracy : {train_accuracy*100:.2f}%\" )\n",
    "print (f\"Val. Accuracy : {val_accuracy*100:.2f}%\" )\n",
    "print (f\"Test Accuracy : {test_accuracy*100:.2f}%\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2122734",
   "metadata": {},
   "source": [
    "We need to implement a loss, to be able to train the classifier.\n",
    "Accuracy is not differentiable, so we use `cross_entropy`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd28cab",
   "metadata": {},
   "source": [
    "##### Calculate Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f9dc8f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "\n",
    "    logits = model(input_batch)[:,-1,:]\n",
    "    loss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9ceede36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "    total_loss = 0\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "    elif num_batches is None:\n",
    "        num_batches = len(data_loader)\n",
    "\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        if i >= num_batches: break\n",
    "\n",
    "        input_batch = input_batch.to(device)\n",
    "        target_batch = target_batch.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            total_loss += calc_loss_batch(input_batch, target_batch, model, device)\n",
    "\n",
    "    return total_loss / num_batches # Average loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6d48fe05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 11.370\n",
      "Validation loss: 11.320\n",
      "Test loss: 11.348\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(\n",
    "        train_loader, model, device, num_batches=5\n",
    "    )\n",
    "    val_loss = calc_loss_loader(val_loader, model, device, num_batches=5)\n",
    "    test_loss = calc_loss_loader(test_loader, model, device, num_batches=5)\n",
    "\n",
    "print(f\"Training loss: {train_loss:.3f}\")\n",
    "print(f\"Validation loss: {val_loss:.3f}\")\n",
    "print(f\"Test loss: {test_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f972a8",
   "metadata": {},
   "source": [
    "### 🏋🏻‍♀️ Fine-tuning the Model to classify SPAM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438bb567",
   "metadata": {},
   "source": [
    "Typical training sequence is described below.  We will then implement the training loop to follow this schema.\n",
    "\n",
    "\n",
    "1) For each training epoch.\n",
    "\n",
    "    2) For each batch in training set.\n",
    "\n",
    "        3) Reset weights.\n",
    "\n",
    "        4) Calculate loss on current batch.\n",
    "\n",
    "        5) Backward pass to calculate gradients.\n",
    "\n",
    "        6) Update weights using gradients.\n",
    "\n",
    "        7) Print training and validation losses.\n",
    "\n",
    "    8) Generate sample text for inspection.\n",
    "\n",
    "9) Repeat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8275df8",
   "metadata": {},
   "source": [
    "##### Train Classifier loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c0f67ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs, eval_freq, eval_iter):\n",
    "\n",
    "    train_accs, val_accs = [], []\n",
    "    train_losses, val_losses = [], []\n",
    "    examples_seen = 0\n",
    "    global_step = -1\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Set model in training mode.\n",
    "        model.train()\n",
    "\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            # Reset weights.\n",
    "            optimizer.zero_grad()\n",
    "            # Compute loss.\n",
    "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "            # Backpropagate loss.\n",
    "            loss.backward()\n",
    "            # Update weights.\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update counters.\n",
    "            examples_seen += input_batch.shape[0]\n",
    "            global_step += 1\n",
    "\n",
    "            # Run evaluations.\n",
    "            if global_step % eval_freq == 0:\n",
    "\n",
    "                def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "                    model.eval()\n",
    "                    with torch.no_grad():\n",
    "                        train_loss = calc_loss_loader(\n",
    "                            train_loader, model, device, num_batches=eval_iter)\n",
    "                        val_loss = calc_loss_loader(\n",
    "                            val_loader, model, device, num_batches=eval_iter)\n",
    "                    model.train()\n",
    "                    return train_loss, val_loss\n",
    "                        \n",
    "                train_loss, val_loss = evaluate_model(\n",
    "                    gpt, train_loader, val_loader, device, eval_iter)\n",
    "                # Append losses to list.\n",
    "                train_losses.append(train_loss)\n",
    "                val_losses.append(val_loss)\n",
    "                # Print reslts.\n",
    "                print(f\"Epoch {epoch+1} (Step {global_step:06d}) : \"\n",
    "                      f\"Train loss {train_loss:.3f}, \"\n",
    "                      f\"Val loss {val_loss:.3f}\"\n",
    "                )\n",
    "\n",
    "        # Calculate accuracy after each epoch.\n",
    "        train_accuracy = calc_accuracy_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "        val_accuracy = calc_accuracy_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "        # Append accs. to list.\n",
    "        train_accs.append(train_accuracy)\n",
    "        val_accs.append(val_accuracy)\n",
    "\n",
    "        # Print evals.\n",
    "        print (f\"Training accuracy at step {epoch} is : {train_accuracy*100:.2f}%\")\n",
    "        print (f\"Val accuracy at step {epoch} is : {val_accuracy*100:.2f}%\")\n",
    "\n",
    "    return train_losses, val_losses, train_accs, val_accs, examples_seen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a27f51",
   "metadata": {},
   "source": [
    "##### Run training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8ed990fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (Step 000000) : Train loss 2.245, Val loss 2.519\n",
      "Epoch 1 (Step 000050) : Train loss 0.261, Val loss 0.230\n",
      "Epoch 1 (Step 000100) : Train loss 0.168, Val loss 0.186\n",
      "Training accuracy at step 0 is : 82.50%\n",
      "Val accuracy at step 0 is : 97.50%\n",
      "Epoch 2 (Step 000150) : Train loss 0.231, Val loss 0.063\n",
      "Epoch 2 (Step 000200) : Train loss 0.075, Val loss 0.145\n",
      "Epoch 2 (Step 000250) : Train loss 0.034, Val loss 0.257\n",
      "Training accuracy at step 1 is : 97.50%\n",
      "Val accuracy at step 1 is : 97.50%\n",
      "Epoch 3 (Step 000300) : Train loss 0.024, Val loss 0.020\n",
      "Epoch 3 (Step 000350) : Train loss 0.144, Val loss 0.054\n",
      "Training accuracy at step 2 is : 95.00%\n",
      "Val accuracy at step 2 is : 97.50%\n",
      "Epoch 4 (Step 000400) : Train loss 0.016, Val loss 0.108\n",
      "Epoch 4 (Step 000450) : Train loss 0.023, Val loss 0.088\n",
      "Epoch 4 (Step 000500) : Train loss 0.019, Val loss 0.091\n",
      "Training accuracy at step 3 is : 95.00%\n",
      "Val accuracy at step 3 is : 97.50%\n",
      "Epoch 5 (Step 000550) : Train loss 0.117, Val loss 0.123\n",
      "Epoch 5 (Step 000600) : Train loss 0.005, Val loss 0.045\n",
      "Training accuracy at step 4 is : 97.50%\n",
      "Val accuracy at step 4 is : 95.00%\n",
      "Training completed in 28.38 minutes.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(gpt.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "num_epochs = 5\n",
    "\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = \\\n",
    "    train_classifier_simple(\n",
    "        gpt, train_loader, val_loader, optimizer, device,\n",
    "        num_epochs=num_epochs, eval_freq=50,\n",
    "        eval_iter=5\n",
    "    )\n",
    "end_time = time.time()\n",
    "execution_time_minutes = (end_time - start_time) / 60\n",
    "print(f\"Training completed in {execution_time_minutes:.2f} minutes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d9b302",
   "metadata": {},
   "source": [
    "##### Plot the classification loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2591b2d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5,3))\n",
    "    \n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, label=f\"Validation {label}\",  linestyle=\"-.\",)\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)\n",
    "    ax2.set_xlabel(\"Examples Seen\")\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
