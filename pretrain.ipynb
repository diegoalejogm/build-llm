{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "0525c683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year 1122\n",
      "years 1123\n",
      "yellow 1124\n",
      "yet 1125\n",
      "you 1126\n",
      "younger 1127\n",
      "your 1128\n",
      "yourself 1129\n",
      "<|endoftext|> 1130\n",
      "<|unk|> 1131\n",
      "[999, 1131, 1131, 1130, 584, 0, 0, 1077, 6]\n",
      "this <|unk|> <|unk|> <|endoftext|> is!! was--\n",
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  198, 11274,  5891,  1576],\n",
      "        [  438,   568,   340,   373],\n",
      "        [  645,  1049,  5975,   284],\n",
      "        [  502,   284,  3285,   326]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   198],\n",
      "        [11274,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "torch.Size([8, 4, 256])\n",
      "torch.Size([4, 256])\n",
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "%run data-processing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "4b21a195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      " usherampires disperseDH\n",
      " usher''''raryexpress\n",
      "Mean:\n",
      "  tensor([-0.3596, -0.2606])\n",
      "Variance :\n",
      "  tensor([0.2015, 0.2673])\n",
      "Norm. Mean:\n",
      "  tensor([    -0.0000,      0.0000], grad_fn=<MeanBackward1>)\n",
      "Norm. Variance :\n",
      "  tensor([1.0000, 1.0000], grad_fn=<VarBackward0>)\n",
      "tensor([[0.2685, 0.7413],\n",
      "        [0.2738, 0.7564],\n",
      "        [0.2668, 0.7366],\n",
      "        [0.2618, 0.7218],\n",
      "        [0.2712, 0.7495]], grad_fn=<MmBackward0>)\n",
      "tensor([[-0.4927, -0.0791],\n",
      "        [-0.4938, -0.0806],\n",
      "        [-0.4924, -0.0851],\n",
      "        [-0.4923, -0.0819],\n",
      "        [-0.4928, -0.0853]], grad_fn=<MmBackward0>)\n",
      "Self Attention V2 output: \n",
      " tensor([[-0.4927, -0.0791],\n",
      "        [-0.4938, -0.0806],\n",
      "        [-0.4924, -0.0851],\n",
      "        [-0.4923, -0.0819],\n",
      "        [-0.4928, -0.0853]], grad_fn=<MmBackward0>)\n",
      "Self Attention V1 output: \n",
      " tensor([[-0.4927, -0.0791],\n",
      "        [-0.4938, -0.0806],\n",
      "        [-0.4924, -0.0851],\n",
      "        [-0.4923, -0.0819],\n",
      "        [-0.4928, -0.0853]], grad_fn=<MmBackward0>)\n",
      "batch.shape: torch.Size([2, 5, 3])\n",
      "contextVecs.shape: torch.Size([2, 5, 2])\n",
      "batch.shape: torch.Size([2, 5, 3])\n",
      "contextVecs.shape: torch.Size([2, 5, 4])\n",
      "batch.shape: torch.Size([2, 5, 3])\n",
      "contextVecs.shape: torch.Size([2, 5, 2])\n",
      "batch.shape: torch.Size([2, 1024, 768])\n",
      "contextVecs.shape: torch.Size([2, 1024, 768])\n",
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n",
      "Output: tensor([[15496,    11,   314,   716, 24111, 43446, 12663, 18650, 28505, 27960]])\n",
      "Output length: 10\n",
      "Hello, I amFrench rebirth fundra Oracle Worm Midnight\n"
     ]
    }
   ],
   "source": [
    "# Load GPT model\n",
    "%run gpt-model.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9e9169",
   "metadata": {},
   "source": [
    "# Generating Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51abd887",
   "metadata": {},
   "source": [
    "Define a functionality that allows encoding and decoding text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "9d8aee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "\n",
    "def textToTokenIds(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    return torch.tensor(encoded).unsqueeze(0)\n",
    "\n",
    "def tokenIdsToText(tokens, tokenizer):\n",
    "    formatted = tokens.squeeze(0).tolist()\n",
    "    return tokenizer.decode(formatted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7a1ec210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Hello world <|endoftext|>\n",
      "Encoded:  tensor([[15496,   995,   220, 50256]])\n",
      "Decoded:  Hello world <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "# Test functionality to encode and decode text.\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "testText = \"Hello world <|endoftext|>\"\n",
    "print(\"Original:\", testText)\n",
    "\n",
    "encoded = textToTokenIds(testText, tokenizer)\n",
    "print(\"Encoded: \", encoded)\n",
    "\n",
    "decoded = tokenIdsToText(encoded, tokenizer)\n",
    "print(\"Decoded: \", decoded)\n",
    "\n",
    "\n",
    "del tokenizer, testText, encoded, decoded\n",
    "# generateText(model, textToTokenIds(testText, tokenizer), 10, cfg[\"contextSize\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2fbdb1",
   "metadata": {},
   "source": [
    "Test functionality to run GPT model to generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7092dbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded output:\n",
      "  tensor([[15496,   995, 27018, 48553, 22819, 39021, 14552, 42861, 23742, 10491,\n",
      "         49354, 30136]])\n",
      "Encoded generated text:\n",
      "  Hello world Featurewrapper CoordHAHAHAHA visalatest screws occasionallyDispatchamsung\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "maxNewTokens = 10\n",
    "testText = \"Hello world\"\n",
    "\n",
    "# Run model\n",
    "encodedOutput = generateText(model, textToTokenIds(testText, tokenizer), maxNewTokens, cfg[\"contextLength\"] )\n",
    "print(\"Encoded output:\\n \", encodedOutput)\n",
    "\n",
    "print(\"Encoded generated text:\\n \", tokenIdsToText(encodedOutput, tokenizer))\n",
    "\n",
    "del tokenizer, maxNewTokens, encodedOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292ced25",
   "metadata": {},
   "source": [
    "## Calculating the text generation loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c445754a",
   "metadata": {},
   "source": [
    "The loss is needed to backpropagate the mistakes.\n",
    "\n",
    "We can use the cross entropy loss, which tries to minimize the difference between two distributions: the model output distribution and the input text distribution (i.e. for evaluation or training). \n",
    "\n",
    "To do this, we first transform the output logits of the model into a probability distribution, using the softmax function. Then, we compute the cross entropy loss.\n",
    "\n",
    "#### Cross Entropy\n",
    "\n",
    "The cross entropy is defined as the negative log likelihood of the probability. \n",
    "- The closer to `1` the predicted probability is, the lower the loss. \n",
    "- Likewise, the predicted ouptut closer to `0`, the higher the loss.\n",
    "\n",
    "We provide batches of inputs to the model, thus we will compute the average cross entropy loss per batch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477d025d",
   "metadata": {},
   "source": [
    "#### Manual implementation\n",
    "First of all, we will implement Cross Entropy manually, to better understand the concept.\n",
    "\n",
    "1. Get logits by running model.\n",
    "2. Compute probabilities as `softmax(logits)`.\n",
    "3. Get `target_probabilities` corresponding to the `target_ids`.\n",
    "4. Compute Cross Entropy as `-log(target_probabilities)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0935204a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      "  ['every effort moves', 'I really like']\n",
      "Prediction:\n",
      "  [' ultrasDERRGy', ' feedingpect 157']\n",
      "Target batch:\n",
      "  tensor([[16833,  3626,  6100],\n",
      "        [   40,  1107,   588]])\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "maxNewTokens = 10\n",
    "inputs = [\"every effort moves\", \"I really like\"]\n",
    "targets = [\"effort moves you\", \"really like chocolate\"]\n",
    "\n",
    "print(\"Inputs:\\n \", inputs)\n",
    "\n",
    "## Generate input logit tensors\n",
    "input_list = [textToTokenIds(i, tokenizer) for i in inputs]\n",
    "input_batch = torch.cat(input_list, dim=0)\n",
    "logits = model(input_batch)\n",
    "prediction = torch.argmax(logits, dim=-1)\n",
    "prediction_txt = [tokenIdsToText(p, tokenizer) for p in prediction]\n",
    "print(\"Prediction:\\n \", prediction_txt)\n",
    "\n",
    "## Generate target tensors\n",
    "target_list = [textToTokenIds(i, tokenizer) for i in inputs]\n",
    "target_batch = torch.cat(target_list, dim=0)\n",
    "print(\"Target batch:\\n \", target_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "73c25c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits:\n",
      "  tensor([[[-0.9445,  1.0687, -0.5287,  ...,  0.7997, -0.3045, -0.1305],\n",
      "         [ 0.3543,  0.1455, -0.2922,  ...,  1.3701,  0.6661, -0.8585],\n",
      "         [ 0.1292, -0.7892, -0.2675,  ...,  1.8117, -0.3191, -0.2270]],\n",
      "\n",
      "        [[-0.5297, -0.1894,  0.0521,  ...,  1.1592,  0.0616, -0.8248],\n",
      "         [-0.3367, -0.2906, -0.4386,  ...,  1.4417,  1.1520, -1.0051],\n",
      "         [-0.0635, -1.0236,  0.1465,  ...,  1.5276, -0.3795,  0.2465]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Probas:\n",
      "  tensor([[[    0.0000,     0.0000,     0.0000,  ...,     0.0000,\n",
      "              0.0000,     0.0000],\n",
      "         [    0.0000,     0.0000,     0.0000,  ...,     0.0001,\n",
      "              0.0000,     0.0000],\n",
      "         [    0.0000,     0.0000,     0.0000,  ...,     0.0001,\n",
      "              0.0000,     0.0000]],\n",
      "\n",
      "        [[    0.0000,     0.0000,     0.0000,  ...,     0.0001,\n",
      "              0.0000,     0.0000],\n",
      "         [    0.0000,     0.0000,     0.0000,  ...,     0.0001,\n",
      "              0.0001,     0.0000],\n",
      "         [    0.0000,     0.0000,     0.0000,  ...,     0.0001,\n",
      "              0.0000,     0.0000]]], grad_fn=<SoftmaxBackward0>)\n",
      "Targer Probas:\n",
      "  tensor([[    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SqueezeBackward1>)\n",
      "Log Probas:\n",
      "  tensor([-10.4004, -11.9913, -10.5911, -10.7188, -10.5306, -10.5762],\n",
      "       grad_fn=<LogBackward0>)\n",
      "Avg. log. Probas:\n",
      "  tensor([-10.4004, -11.9913, -10.5911, -10.7188, -10.5306, -10.5762],\n",
      "       grad_fn=<LogBackward0>)\n",
      "Cross Entropy Loss:\n",
      "  tensor(10.8014, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## Fetch probabilities for target tensors\n",
    "print(\"Logits:\\n \", logits)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(\"Probas:\\n \", probas)\n",
    "target_probas = torch.gather(probas, -1, target_batch.unsqueeze(-1)).squeeze(-1)\n",
    "print(\"Targer Probas:\\n \", target_probas)\n",
    "\n",
    "## Compute cross entropy\n",
    "log_probas = torch.log(target_probas.flatten())\n",
    "print(\"Log Probas:\\n \", log_probas)\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(\"Avg. log. Probas:\\n \", log_probas)\n",
    "neg_avg_log_probas = torch.mean(avg_log_probas) * -1\n",
    "print(\"Cross Entropy Loss:\\n \", neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29efb36",
   "metadata": {},
   "source": [
    "#### Compute using Torch Cross Entropy function\n",
    "\n",
    "Now that we've implemented the cross entropy manually, we can just use the torch available functions to confirm it was correctly implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "42b96bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.8014, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0,1)\n",
    "targets_flat = target_batch.flatten()\n",
    "torch.nn.functional.cross_entropy(logits_flat, targets_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99ef423",
   "metadata": {},
   "source": [
    "## Training & Validation losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196561d0",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bf425c",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b353d13",
   "metadata": {},
   "source": [
    "##### Load text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "48830396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5477\n"
     ]
    }
   ],
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da36141f",
   "metadata": {},
   "source": [
    "##### Split train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "13961777",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75b6853",
   "metadata": {},
   "source": [
    "##### Create dataloaders using splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "edb66ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=cfg[\"contextLength\"],\n",
    "    stride=cfg[\"contextLength\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=cfg[\"contextLength\"],\n",
    "    stride=cfg[\"contextLength\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f34aa66",
   "metadata": {},
   "source": [
    "##### Display loader contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "d56b4219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7024952",
   "metadata": {},
   "source": [
    "### Loss Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5f65f1",
   "metadata": {},
   "source": [
    "##### Batch loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "c444ec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a given batch, compute the cross entropy.\n",
    "def calc_loss_batch(input_batch: torch.Tensor, target_batch: torch.Tensor, model: torch.nn.Module, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    # Run model.\n",
    "    logits = model(input_batch)\n",
    "    # Compute cross-entropy loss.\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b165c99",
   "metadata": {},
   "source": [
    "##### Data loader loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f2c41693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the loss for a given data_loader.\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=torch.inf):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    # Select num_batches to be at most len(data_loader)/\n",
    "    num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "    # Iterate through batches and compute sum loss.\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        loss = calc_loss_batch(\n",
    "            input_batch, target_batch, model, device\n",
    "        )\n",
    "        total_loss += loss.item()\n",
    "    # Return avg. loss.\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff0c047",
   "metadata": {},
   "source": [
    "##### Compute initial model loss\n",
    "\n",
    "Run calc_loss_loader() on the train and eval sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a373f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.06528965549336539\n",
      "Validation loss: 7.211176872253418\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b46563",
   "metadata": {},
   "source": [
    "### Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7057f0",
   "metadata": {},
   "source": [
    "##### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d80ab840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the train and validation loaders. Runs only on the `eval_iter` number of batches.\n",
    "# Returns the train and validation losses.\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5011ca",
   "metadata": {},
   "source": [
    "##### Generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "d539914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates text.\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
    "    model.eval()\n",
    "    context_size = model.posEmbed.weight.shape[0]\n",
    "    encoded = textToTokenIds(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generateText(\n",
    "            model=model, idx=encoded,\n",
    "            maxNewTokens=50, contextSize=context_size\n",
    "        )\n",
    "    decoded_text = tokenIdsToText(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a8c39b",
   "metadata": {},
   "source": [
    "##### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "81f2fc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains the model. \n",
    "# Returns the train, validation losses, and a list of all the tokens seen during training.\n",
    "def train_model_simple(model, train_loader, val_loader,\n",
    "                       optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    def print_evals():\n",
    "        train_loss, val_loss = evaluate_model(\n",
    "            model, train_loader, val_loader, device, eval_iter\n",
    "        )\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        track_tokens_seen.append(tokens_seen)\n",
    "        print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "            f\"Train loss {train_loss:.3f}, \"\n",
    "            f\"Val loss {val_loss:.3f}\"\n",
    "        )\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(\n",
    "                    input_batch, target_batch, model, device\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Print evals.\n",
    "            if global_step % eval_freq == 0:\n",
    "                print_evals()\n",
    "\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aa3a77",
   "metadata": {},
   "source": [
    "##### Load Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab273422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tokEmbed): Embedding(50257, 768)\n",
       "  (posEmbed): Embedding(256, 768)\n",
       "  (trfBlocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (layerNorm1): LayerNorm()\n",
       "      (layerNorm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (feedfwd): FeedForwardModule(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (attention): MultiHeadAttention(\n",
       "        (wKeys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wQueries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wValues): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linearProj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (layerNorm1): LayerNorm()\n",
       "      (layerNorm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (feedfwd): FeedForwardModule(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (attention): MultiHeadAttention(\n",
       "        (wKeys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wQueries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wValues): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linearProj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (layerNorm1): LayerNorm()\n",
       "      (layerNorm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (feedfwd): FeedForwardModule(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (attention): MultiHeadAttention(\n",
       "        (wKeys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wQueries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wValues): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linearProj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (layerNorm1): LayerNorm()\n",
       "      (layerNorm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (feedfwd): FeedForwardModule(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (attention): MultiHeadAttention(\n",
       "        (wKeys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wQueries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wValues): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linearProj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (layerNorm1): LayerNorm()\n",
       "      (layerNorm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (feedfwd): FeedForwardModule(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (attention): MultiHeadAttention(\n",
       "        (wKeys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wQueries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wValues): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linearProj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (layerNorm1): LayerNorm()\n",
       "      (layerNorm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (feedfwd): FeedForwardModule(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (attention): MultiHeadAttention(\n",
       "        (wKeys): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wQueries): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (wValues): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linearProj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (finalNorm): LayerNorm()\n",
       "  (outLayer): Linear(in_features=768, out_features=50257, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "cfg = {\n",
    "    \"vocabSize\": 50257, # Number of tokens in vocabulary.\n",
    "    \"contextLength\": 256, # Max. number of tokens the LLM sees per run.\n",
    "    \"embDim\": 768, # Size of the internal. embeddings used in the LLM attention mechanism.\n",
    "    \"nLayers\" : 6, # Number of transformer layers.\n",
    "    \"dropRate\": 0.1, # Feature dropout rate.\n",
    "    \"nHeads\": 12 # Num. Attention heads per multi-head attention block    \n",
    "}\n",
    "\n",
    "model = GPTModel(cfg)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076b3c7d",
   "metadata": {},
   "source": [
    "##### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "9675e871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 18.273, Val loss 10.211\n",
      "Ep 1 (Step 000005): Train loss 14.507, Val loss 8.323\n",
      "Every effort moves you                                                  \n",
      "Ep 2 (Step 000010): Train loss 12.286, Val loss 7.214\n",
      "Ep 2 (Step 000015): Train loss 11.207, Val loss 6.775\n",
      "Every effort moves you                                                  \n",
      "Ep 3 (Step 000020): Train loss 10.777, Val loss 6.706\n",
      "Ep 3 (Step 000025): Train loss 10.089, Val loss 6.647\n",
      "Every effort moves you. \"--. \"--. \"--. \". \"--I--. \"----I----. \" to the \"-- the \". \"--I, and, and--\n",
      "Ep 4 (Step 000030): Train loss 9.877, Val loss 6.575\n",
      "Ep 4 (Step 000035): Train loss 9.060, Val loss 6.507\n",
      "Every effort moves you.                                                 \n",
      "Ep 5 (Step 000040): Train loss 7.895, Val loss 6.439\n",
      "Every effort moves you know he had been. \"I \"Oh, I was his a little was \"Oh, and I was a little the--and the \"Oh, I had been. \"I had been \"I \"I\n",
      "Ep 6 (Step 000045): Train loss 7.327, Val loss 6.409\n",
      "Ep 6 (Step 000050): Train loss 6.466, Val loss 6.324\n",
      "Every effort moves you know he \"I of the \"Oh, and I was his own of the \"Oh, and he was, I felt to have the \"Oh, I had to the \"I had to the \"Oh, he\n",
      "Ep 7 (Step 000055): Train loss 5.641, Val loss 6.295\n",
      "Ep 7 (Step 000060): Train loss 4.731, Val loss 6.316\n",
      "Every effort moves you know he had the room. \"--and it was to go a little said. \"Oh, a little--his own \"I didn't know it the  \"I was \"--I turned back to the he\n",
      "Ep 8 (Step 000065): Train loss 4.030, Val loss 6.398\n",
      "Ep 8 (Step 000070): Train loss 3.395, Val loss 6.397\n",
      "Every effort moves you know he said, and the surest way of the \"Oh, and he \"Oh, and uncertain.  \"--and yet not to lose an    \"Ah, and in the ensuing a little it to\n",
      "Ep 9 (Step 000075): Train loss 2.775, Val loss 6.471\n",
      "Ep 9 (Step 000080): Train loss 2.280, Val loss 6.463\n",
      "Every effort moves you know Mrs. Stroud so when she \"Oh, and I had been me out longed by the the latter, and brown and Mrs. the_ fashionable painter.\"  \"Ah, and Mrs. He showed it to\n",
      "Ep 10 (Step 000085): Train loss 1.804, Val loss 6.602\n",
      "Every effort moves you know Mrs. the room.   \"Oh, I had been me out long ago,\" he said lightly; then beneath the picture.  \"How it happened? I can tell you in five minutes--and it didn't take\n",
      "Ep 11 (Step 000090): Train loss 1.348, Val loss 6.599\n",
      "Ep 11 (Step 000095): Train loss 1.056, Val loss 6.759\n",
      "Every effort moves you know Mrs. Stroud so when she began to stammer something about her poverty. I remember getting off a prodigious phrase about the honour being _mine_--oh, I was tried to hide her nervousness;\n",
      "Ep 12 (Step 000100): Train loss 0.835, Val loss 6.767\n",
      "Ep 12 (Step 000105): Train loss 0.650, Val loss 6.888\n",
      "Every effort moves you know; and the room.   \"Oh, Rickham found me out long ago,\" he said lightly; then, passing his arm through mine: \"Come and see the rest of old Venetian point. \" \n",
      "Ep 13 (Step 000110): Train loss 0.522, Val loss 6.881\n",
      "Ep 13 (Step 000115): Train loss 0.429, Val loss 7.030\n",
      "Every effort moves you know.\" She raised her eyebrows with a hint of good-humoured surprise.  \"Oh, he doesn't _have_ to now, you know; and I want him to enjoy himself,\" she said quite simply. \n",
      "Ep 14 (Step 000120): Train loss 0.359, Val loss 7.068\n",
      "Ep 14 (Step 000125): Train loss 0.317, Val loss 7.130\n",
      "Every effort moves you know; and thought it the surest way of good-humoured surprise.  \"Oh, he doesn't _have_ to now, you know; and I want him to enjoy himself,\" she said quite simply. \n",
      "Ep 15 (Step 000130): Train loss 0.254, Val loss 7.225\n",
      "Every effort moves you know how of the donkey. \"There were days when I couldn't look at that thing--couldn't face it. But I forced myself to put it here; and now it's cured me--cured me. That's\n",
      "Ep 16 (Step 000135): Train loss 0.205, Val loss 7.187\n",
      "Ep 16 (Step 000140): Train loss 0.168, Val loss 7.260\n",
      "Every effort moves you know; and myself borne thither the next day.  I found the couple at tea beneath their palm-trees; and Mrs. Gisburn's welcome was so genial that, in the ensuing weeks, I \n",
      "Ep 17 (Step 000145): Train loss 0.154, Val loss 7.294\n",
      "Ep 17 (Step 000150): Train loss 0.129, Val loss 7.391\n",
      "Every effort moves you know.\" She raised her eyebrows with a hint of good-humoured surprise.  thing--couldn't face it. But I forced myself to put it here; and now it's cured me--cured me. That's\n",
      "Ep 18 (Step 000155): Train loss 0.117, Val loss 7.482\n",
      "Ep 18 (Step 000160): Train loss 0.118, Val loss 7.400\n",
      "Every effort moves you know.\" She raised her eyebrows with a hint of good-humoured surprise.  \"Oh, he doesn't _have_ to now, you know; and I want him to enjoy himself,\" she said quite simply. \n",
      "Ep 19 (Step 000165): Train loss 0.100, Val loss 7.429\n",
      "Ep 19 (Step 000170): Train loss 0.086, Val loss 7.553\n",
      "Every effort moves you know how of the donkey. \"There were days when I couldn't look at that thing--couldn't face it. But I forced myself to put it here; and now it's cured me--cured me. That's\n",
      "Ep 20 (Step 000175): Train loss 0.071, Val loss 7.547\n",
      "Every effort moves you know.\" of the donkey. \"There were days when I couldn't look at that thing--couldn't face it. But I forced myself to put it here; and now it's cured me--cured me. That's\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=0.0004, weight_decay=0.1\n",
    ")\n",
    "num_epochs = 20\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a2f0a3",
   "metadata": {},
   "source": [
    "##### Display Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "5b56112a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def _to_list(x):\n",
    "    if torch.is_tensor(x):\n",
    "        # avoids .numpy() so no NumPy dependency\n",
    "        return x.detach().cpu().tolist()\n",
    "    # handle lists/tuples already\n",
    "    return x\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(_to_list(epochs_tensor), _to_list(tokens_seen), _to_list(train_losses), _to_list(val_losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e66834e",
   "metadata": {},
   "source": [
    "##### Generate new output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313413eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There: \"We shall not look upon its like again\"?  Well!--even through the prism of Hermia's tears I felt able to face the fact with equanimity. Poor Jack Gisburn! The women had made him--\n"
     ]
    }
   ],
   "source": [
    "generate_and_print_sample(model, tokenizer, device, \"There\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
