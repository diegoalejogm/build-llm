{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0525c683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year 1122\n",
      "years 1123\n",
      "yellow 1124\n",
      "yet 1125\n",
      "you 1126\n",
      "younger 1127\n",
      "your 1128\n",
      "yourself 1129\n",
      "<|endoftext|> 1130\n",
      "<|unk|> 1131\n",
      "[999, 1131, 1131, 1130, 584, 0, 0, 1077, 6]\n",
      "this <|unk|> <|unk|> <|endoftext|> is!! was--\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.6 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"/Users/diego/.pyenv/versions/3.10.18/lib/python3.10/runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"/Users/diego/.pyenv/versions/3.10.18/lib/python3.10/runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/diego/.pyenv/versions/3.10.18/lib/python3.10/asyncio/base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/diego/.pyenv/versions/3.10.18/lib/python3.10/asyncio/base_events.py\", line 1909, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/diego/.pyenv/versions/3.10.18/lib/python3.10/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/mj/n091p3r94n30mbbxvfqpsxth0000gn/T/ipykernel_94046/3125812683.py\", line 1, in <module>\n",
      "    get_ipython().run_line_magic('run', 'data-processing.ipynb')\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 2482, in run_line_magic\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/IPython/core/magics/execution.py\", line 741, in run\n",
      "    self.shell.safe_execfile_ipy(filename, raise_exceptions=True)\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3005, in safe_execfile_ipy\n",
      "    result = self.run_cell(cell, silent=True, shell_futures=shell_futures)\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3077, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3132, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3336, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3519, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py\", line 3579, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/mj/n091p3r94n30mbbxvfqpsxth0000gn/T/ipykernel_94046/3737033689.py\", line 3, in <module>\n",
      "    from torch.utils.data import Dataset\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/diego/Documents/Projects/build-llm/.venv/lib/python3.10/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      " tensor([[   40,   367,  2885,  1464],\n",
      "        [ 1807,  3619,   402,   271],\n",
      "        [10899,  2138,   257,  7026],\n",
      "        [15632,   438,  2016,   257],\n",
      "        [  198, 11274,  5891,  1576],\n",
      "        [  438,   568,   340,   373],\n",
      "        [  645,  1049,  5975,   284],\n",
      "        [  502,   284,  3285,   326]])\n",
      "\n",
      "Targets:\n",
      " tensor([[  367,  2885,  1464,  1807],\n",
      "        [ 3619,   402,   271, 10899],\n",
      "        [ 2138,   257,  7026, 15632],\n",
      "        [  438,  2016,   257,   198],\n",
      "        [11274,  5891,  1576,   438],\n",
      "        [  568,   340,   373,   645],\n",
      "        [ 1049,  5975,   284,   502],\n",
      "        [  284,  3285,   326,    11]])\n",
      "torch.Size([8, 4, 256])\n",
      "torch.Size([4, 256])\n",
      "torch.Size([8, 4, 256])\n"
     ]
    }
   ],
   "source": [
    "%run data-processing.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b21a195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6109, 3626, 6100,  345],\n",
      "        [6109, 1110, 6622,  257]])\n",
      "next Commonsanks Lean\n",
      " nort Tight selectedcin\n",
      "Mean:\n",
      "  tensor([-0.3596, -0.2606])\n",
      "Variance :\n",
      "  tensor([0.2015, 0.2673])\n",
      "Norm. Mean:\n",
      "  tensor([    -0.0000,      0.0000], grad_fn=<MeanBackward1>)\n",
      "Norm. Variance :\n",
      "  tensor([1.0000, 1.0000], grad_fn=<VarBackward0>)\n",
      "tensor([[0.2685, 0.7413],\n",
      "        [0.2738, 0.7564],\n",
      "        [0.2668, 0.7366],\n",
      "        [0.2618, 0.7218],\n",
      "        [0.2712, 0.7495]], grad_fn=<MmBackward0>)\n",
      "tensor([[-0.4927, -0.0791],\n",
      "        [-0.4938, -0.0806],\n",
      "        [-0.4924, -0.0851],\n",
      "        [-0.4923, -0.0819],\n",
      "        [-0.4928, -0.0853]], grad_fn=<MmBackward0>)\n",
      "Self Attention V2 output: \n",
      " tensor([[-0.4927, -0.0791],\n",
      "        [-0.4938, -0.0806],\n",
      "        [-0.4924, -0.0851],\n",
      "        [-0.4923, -0.0819],\n",
      "        [-0.4928, -0.0853]], grad_fn=<MmBackward0>)\n",
      "Self Attention V1 output: \n",
      " tensor([[-0.4927, -0.0791],\n",
      "        [-0.4938, -0.0806],\n",
      "        [-0.4924, -0.0851],\n",
      "        [-0.4923, -0.0819],\n",
      "        [-0.4928, -0.0853]], grad_fn=<MmBackward0>)\n",
      "batch.shape: torch.Size([2, 5, 3])\n",
      "contextVecs.shape: torch.Size([2, 5, 2])\n",
      "batch.shape: torch.Size([2, 5, 3])\n",
      "contextVecs.shape: torch.Size([2, 5, 4])\n",
      "batch.shape: torch.Size([2, 5, 3])\n",
      "contextVecs.shape: torch.Size([2, 5, 2])\n",
      "batch.shape: torch.Size([2, 1024, 768])\n",
      "contextVecs.shape: torch.Size([2, 1024, 768])\n",
      "encoded: [15496, 11, 314, 716]\n",
      "encoded_tensor.shape: torch.Size([1, 4])\n",
      "Output: tensor([[15496,    11,   314,   716, 24111, 43446, 12663, 18650, 28505, 27960]])\n",
      "Output length: 10\n",
      "Hello, I amFrench rebirth fundra Oracle Worm Midnight\n"
     ]
    }
   ],
   "source": [
    "# Load GPT model\n",
    "%run gpt-model.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9e9169",
   "metadata": {},
   "source": [
    "# Generating Text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51abd887",
   "metadata": {},
   "source": [
    "Define a functionality that allows encoding and decoding text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d8aee08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import torch\n",
    "\n",
    "def textToTokenIds(text, tokenizer):\n",
    "    encoded = tokenizer.encode(text, allowed_special={'<|endoftext|>'})\n",
    "    return torch.tensor(encoded).unsqueeze(0)\n",
    "\n",
    "def tokenIdsToText(tokens, tokenizer):\n",
    "    formatted = tokens.squeeze(0).tolist()\n",
    "    return tokenizer.decode(formatted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a1ec210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Hello world <|endoftext|>\n",
      "Encoded:  tensor([[15496,   995,   220, 50256]])\n",
      "Decoded:  Hello world <|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "# Test functionality to encode and decode text.\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "testText = \"Hello world <|endoftext|>\"\n",
    "print(\"Original:\", testText)\n",
    "\n",
    "encoded = textToTokenIds(testText, tokenizer)\n",
    "print(\"Encoded: \", encoded)\n",
    "\n",
    "decoded = tokenIdsToText(encoded, tokenizer)\n",
    "print(\"Decoded: \", decoded)\n",
    "\n",
    "\n",
    "del tokenizer, testText, encoded, decoded\n",
    "# generateText(model, textToTokenIds(testText, tokenizer), 10, cfg[\"contextSize\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2fbdb1",
   "metadata": {},
   "source": [
    "Test functionality to run GPT model to generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7092dbbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded output:\n",
      "  tensor([[15496,   995, 27018, 48553, 22819, 39021, 14552, 42861, 23742, 10491,\n",
      "         49354, 30136]])\n",
      "Encoded generated text:\n",
      "  Hello world Featurewrapper CoordHAHAHAHA visalatest screws occasionallyDispatchamsung\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "maxNewTokens = 10\n",
    "testText = \"Hello world\"\n",
    "\n",
    "# Run model\n",
    "encodedOutput = generateText(model, textToTokenIds(testText, tokenizer), maxNewTokens, cfg[\"contextLength\"] )\n",
    "print(\"Encoded output:\\n \", encodedOutput)\n",
    "\n",
    "print(\"Encoded generated text:\\n \", tokenIdsToText(encodedOutput, tokenizer))\n",
    "\n",
    "del tokenizer, maxNewTokens, encodedOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292ced25",
   "metadata": {},
   "source": [
    "## Calculating the text generation loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c445754a",
   "metadata": {},
   "source": [
    "The loss is needed to backpropagate the mistakes.\n",
    "\n",
    "We can use the cross entropy loss, which tries to minimize the difference between two distributions: the model output distribution and the input text distribution (i.e. for evaluation or training). \n",
    "\n",
    "To do this, we first transform the output logits of the model into a probability distribution, using the softmax function. Then, we compute the cross entropy loss.\n",
    "\n",
    "#### Cross Entropy\n",
    "\n",
    "The cross entropy is defined as the negative log likelihood of the probability. \n",
    "- The closer to `1` the predicted probability is, the lower the loss. \n",
    "- Likewise, the predicted ouptut closer to `0`, the higher the loss.\n",
    "\n",
    "We provide batches of inputs to the model, thus we will compute the average cross entropy loss per batch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477d025d",
   "metadata": {},
   "source": [
    "#### Manual implementation\n",
    "First of all, we will implement Cross Entropy manually, to better understand the concept.\n",
    "\n",
    "1. Get logits by running model.\n",
    "2. Compute probabilities as `softmax(logits)`.\n",
    "3. Get `target_probabilities` corresponding to the `target_ids`.\n",
    "4. Compute Cross Entropy as `-log(target_probabilities)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0935204a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      "  ['every effort moves', 'I really like']\n",
      "Prediction:\n",
      "  [' ultrasDERRGy', ' feedingpect 157']\n",
      "Target batch:\n",
      "  tensor([[16833,  3626,  6100],\n",
      "        [   40,  1107,   588]])\n"
     ]
    }
   ],
   "source": [
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "maxNewTokens = 10\n",
    "inputs = [\"every effort moves\", \"I really like\"]\n",
    "targets = [\"effort moves you\", \"really like chocolate\"]\n",
    "\n",
    "print(\"Inputs:\\n \", inputs)\n",
    "\n",
    "## Generate input logit tensors\n",
    "input_list = [textToTokenIds(i, tokenizer) for i in inputs]\n",
    "input_batch = torch.cat(input_list, dim=0)\n",
    "logits = model(input_batch)\n",
    "prediction = torch.argmax(logits, dim=-1)\n",
    "prediction_txt = [tokenIdsToText(p, tokenizer) for p in prediction]\n",
    "print(\"Prediction:\\n \", prediction_txt)\n",
    "\n",
    "## Generate target tensors\n",
    "target_list = [textToTokenIds(i, tokenizer) for i in inputs]\n",
    "target_batch = torch.cat(target_list, dim=0)\n",
    "print(\"Target batch:\\n \", target_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73c25c0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits:\n",
      "  tensor([[[-0.9445,  1.0687, -0.5287,  ...,  0.7997, -0.3045, -0.1305],\n",
      "         [ 0.3543,  0.1455, -0.2922,  ...,  1.3701,  0.6661, -0.8585],\n",
      "         [ 0.1292, -0.7892, -0.2675,  ...,  1.8117, -0.3191, -0.2270]],\n",
      "\n",
      "        [[-0.5297, -0.1894,  0.0521,  ...,  1.1592,  0.0616, -0.8248],\n",
      "         [-0.3367, -0.2906, -0.4386,  ...,  1.4417,  1.1520, -1.0051],\n",
      "         [-0.0635, -1.0236,  0.1465,  ...,  1.5276, -0.3795,  0.2465]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "Probas:\n",
      "  tensor([[[    0.0000,     0.0000,     0.0000,  ...,     0.0000,\n",
      "              0.0000,     0.0000],\n",
      "         [    0.0000,     0.0000,     0.0000,  ...,     0.0001,\n",
      "              0.0000,     0.0000],\n",
      "         [    0.0000,     0.0000,     0.0000,  ...,     0.0001,\n",
      "              0.0000,     0.0000]],\n",
      "\n",
      "        [[    0.0000,     0.0000,     0.0000,  ...,     0.0001,\n",
      "              0.0000,     0.0000],\n",
      "         [    0.0000,     0.0000,     0.0000,  ...,     0.0001,\n",
      "              0.0001,     0.0000],\n",
      "         [    0.0000,     0.0000,     0.0000,  ...,     0.0001,\n",
      "              0.0000,     0.0000]]], grad_fn=<SoftmaxBackward0>)\n",
      "Targer Probas:\n",
      "  tensor([[    0.0000,     0.0000,     0.0000],\n",
      "        [    0.0000,     0.0000,     0.0000]], grad_fn=<SqueezeBackward1>)\n",
      "Log Probas:\n",
      "  tensor([-10.4004, -11.9913, -10.5911, -10.7188, -10.5306, -10.5762],\n",
      "       grad_fn=<LogBackward0>)\n",
      "Avg. log. Probas:\n",
      "  tensor([-10.4004, -11.9913, -10.5911, -10.7188, -10.5306, -10.5762],\n",
      "       grad_fn=<LogBackward0>)\n",
      "Cross Entropy Loss:\n",
      "  tensor(10.8014, grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## Fetch probabilities for target tensors\n",
    "print(\"Logits:\\n \", logits)\n",
    "probas = torch.softmax(logits, dim=-1)\n",
    "print(\"Probas:\\n \", probas)\n",
    "target_probas = torch.gather(probas, -1, target_batch.unsqueeze(-1)).squeeze(-1)\n",
    "print(\"Targer Probas:\\n \", target_probas)\n",
    "\n",
    "## Compute cross entropy\n",
    "log_probas = torch.log(target_probas.flatten())\n",
    "print(\"Log Probas:\\n \", log_probas)\n",
    "avg_log_probas = torch.mean(log_probas)\n",
    "print(\"Avg. log. Probas:\\n \", log_probas)\n",
    "neg_avg_log_probas = torch.mean(avg_log_probas) * -1\n",
    "print(\"Cross Entropy Loss:\\n \", neg_avg_log_probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29efb36",
   "metadata": {},
   "source": [
    "#### Compute using Torch Cross Entropy function\n",
    "\n",
    "Now that we've implemented the cross entropy manually, we can just use the torch available functions to confirm it was correctly implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42b96bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.8014, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0,1)\n",
    "targets_flat = target_batch.flatten()\n",
    "torch.nn.functional.cross_entropy(logits_flat, targets_flat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99ef423",
   "metadata": {},
   "source": [
    "## Training & Validation losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196561d0",
   "metadata": {},
   "source": [
    "## Training Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bf425c",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b353d13",
   "metadata": {},
   "source": [
    "##### Load text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48830396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Characters: 20479\n",
      "Tokens: 5477\n"
     ]
    }
   ],
   "source": [
    "file_path = \"the-verdict.txt\"\n",
    "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "    text_data = file.read()\n",
    "total_characters = len(text_data)\n",
    "total_tokens = len(tokenizer.encode(text_data))\n",
    "print(\"Characters:\", total_characters)\n",
    "print(\"Tokens:\", total_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da36141f",
   "metadata": {},
   "source": [
    "##### Split train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13961777",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.90\n",
    "split_idx = int(train_ratio * len(text_data))\n",
    "train_data = text_data[:split_idx]\n",
    "val_data = text_data[split_idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75b6853",
   "metadata": {},
   "source": [
    "##### Create dataloaders using splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "edb66ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "train_loader = create_dataloader_v1(\n",
    "    train_data,\n",
    "    batch_size=2,\n",
    "    max_length=cfg[\"contextLength\"],\n",
    "    stride=cfg[\"contextLength\"],\n",
    "    drop_last=True,\n",
    "    shuffle=True,\n",
    "    num_workers=0\n",
    ")\n",
    "val_loader = create_dataloader_v1(\n",
    "    val_data,\n",
    "    batch_size=2,\n",
    "    max_length=cfg[\"contextLength\"],\n",
    "    stride=cfg[\"contextLength\"],\n",
    "    drop_last=False,\n",
    "    shuffle=False,\n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f34aa66",
   "metadata": {},
   "source": [
    "##### Display loader contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d56b4219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n",
      "\n",
      "Validation loader:\n",
      "torch.Size([2, 256]) torch.Size([2, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"Train loader:\")\n",
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "print(\"\\nValidation loader:\")\n",
    "for x, y in val_loader:\n",
    "    print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7024952",
   "metadata": {},
   "source": [
    "### Loss Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5f65f1",
   "metadata": {},
   "source": [
    "##### Batch loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c444ec20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For a given batch, compute the cross entropy.\n",
    "def calc_loss_batch(input_batch: torch.Tensor, target_batch: torch.Tensor, model: torch.nn.Module, device):\n",
    "    input_batch = input_batch.to(device)\n",
    "    target_batch = target_batch.to(device)\n",
    "    # Run model.\n",
    "    logits = model(input_batch)\n",
    "    # Compute cross-entropy loss.\n",
    "    loss = torch.nn.functional.cross_entropy(\n",
    "        logits.flatten(0, 1), target_batch.flatten()\n",
    "    )\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b165c99",
   "metadata": {},
   "source": [
    "##### Data loader loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f2c41693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the loss for a given data_loader.\n",
    "def calc_loss_loader(data_loader, model, device, num_batches=torch.inf):\n",
    "    total_loss = 0.\n",
    "    if len(data_loader) == 0:\n",
    "        return float(\"nan\")\n",
    "\n",
    "    # Select num_batches to be at most len(data_loader)/\n",
    "    num_batches = min(num_batches, len(data_loader))\n",
    "\n",
    "    # Iterate through batches and compute sum loss.\n",
    "    for i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "        loss = calc_loss_batch(\n",
    "            input_batch, target_batch, model, device\n",
    "        )\n",
    "        total_loss += loss.item()\n",
    "    # Return avg. loss.\n",
    "    return total_loss / num_batches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff0c047",
   "metadata": {},
   "source": [
    "##### Compute initial model loss\n",
    "\n",
    "Run calc_loss_loader() on the train and eval sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12a373f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 11.026515324910482\n",
      "Validation loss: 10.95970630645752\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    train_loss = calc_loss_loader(train_loader, model, device)\n",
    "    val_loss = calc_loss_loader(val_loader, model, device)\n",
    "\n",
    "print(\"Training loss:\", train_loss)\n",
    "print(\"Validation loss:\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b46563",
   "metadata": {},
   "source": [
    "### Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7057f0",
   "metadata": {},
   "source": [
    "##### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d80ab840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the train and validation loaders. Runs only on the `eval_iter` number of batches.\n",
    "# Returns the train and validation losses.\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        train_loss = calc_loss_loader(\n",
    "            train_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "        val_loss = calc_loss_loader(\n",
    "            val_loader, model, device, num_batches=eval_iter\n",
    "        )\n",
    "    model.train()\n",
    "    return train_loss, val_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5011ca",
   "metadata": {},
   "source": [
    "##### Generate text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d539914c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates text.\n",
    "def generate_and_print_sample(model, tokenizer, device, start_context, temperature : int = 0.0, top_k=None, eos_id=None):\n",
    "    model.eval()\n",
    "    context_size = model.posEmbed.weight.shape[0]\n",
    "    encoded = textToTokenIds(start_context, tokenizer).to(device)\n",
    "    with torch.no_grad():\n",
    "        token_ids = generateText(\n",
    "            model=model, idx=encoded,\n",
    "            maxNewTokens=50, contextSize=context_size,\n",
    "            temperature=temperature, top_k=top_k\n",
    "        )\n",
    "    decoded_text = tokenIdsToText(token_ids, tokenizer)\n",
    "    print(decoded_text.replace(\"\\n\", \" \"))\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a8c39b",
   "metadata": {},
   "source": [
    "##### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81f2fc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains the model. \n",
    "# Returns the train, validation losses, and a list of all the tokens seen during training.\n",
    "def train_model_simple(model, train_loader, val_loader,\n",
    "                       optimizer, device, num_epochs,\n",
    "                       eval_freq, eval_iter, start_context, tokenizer):\n",
    "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
    "    tokens_seen, global_step = 0, -1\n",
    "\n",
    "    def print_evals():\n",
    "        train_loss, val_loss = evaluate_model(\n",
    "            model, train_loader, val_loader, device, eval_iter\n",
    "        )\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        track_tokens_seen.append(tokens_seen)\n",
    "        print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
    "            f\"Train loss {train_loss:.3f}, \"\n",
    "            f\"Val loss {val_loss:.3f}\"\n",
    "        )\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for input_batch, target_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            loss = calc_loss_batch(\n",
    "                    input_batch, target_batch, model, device\n",
    "            )\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            tokens_seen += input_batch.numel()\n",
    "            global_step += 1\n",
    "\n",
    "            # Print evals.\n",
    "            if global_step % eval_freq == 0:\n",
    "                print_evals()\n",
    "\n",
    "        generate_and_print_sample(\n",
    "            model, tokenizer, device, start_context\n",
    "        )\n",
    "    return train_losses, val_losses, track_tokens_seen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18aa3a77",
   "metadata": {},
   "source": [
    "##### Load Training Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab273422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tokEmbed): Embedding(50257, 256)\n",
       "  (posEmbed): Embedding(256, 256)\n",
       "  (trfBlocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (layerNorm1): LayerNorm()\n",
       "      (layerNorm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (feedfwd): FeedForwardModule(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (attention): MultiHeadAttention(\n",
       "        (wKeys): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (wQueries): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (wValues): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linearProj): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (layerNorm1): LayerNorm()\n",
       "      (layerNorm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (feedfwd): FeedForwardModule(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (attention): MultiHeadAttention(\n",
       "        (wKeys): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (wQueries): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (wValues): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linearProj): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (layerNorm1): LayerNorm()\n",
       "      (layerNorm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (feedfwd): FeedForwardModule(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (attention): MultiHeadAttention(\n",
       "        (wKeys): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (wQueries): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (wValues): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linearProj): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (layerNorm1): LayerNorm()\n",
       "      (layerNorm2): LayerNorm()\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "      (feedfwd): FeedForwardModule(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (attention): MultiHeadAttention(\n",
       "        (wKeys): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (wQueries): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (wValues): Linear(in_features=256, out_features=256, bias=False)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "        (linearProj): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (finalNorm): LayerNorm()\n",
       "  (outLayer): Linear(in_features=256, out_features=50257, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "\n",
    "cfg = {\n",
    "    \"vocabSize\": 50257, # Number of tokens in vocabulary.\n",
    "    \"contextLength\": 256, # Max. number of tokens the LLM sees per run.\n",
    "    \"embDim\": 256, # Size of the internal. embeddings used in the LLM attention mechanism.\n",
    "    \"nLayers\" : 4, # Number of transformer layers.\n",
    "    \"dropRate\": 0.1, # Feature dropout rate.\n",
    "    \"nHeads\": 4 # Num. Attention heads per multi-head attention block    \n",
    "}\n",
    "# cfg = {\n",
    "#     \"vocabSize\": 50257, # Number of tokens in vocabulary.\n",
    "#     \"contextLength\": 256, # Max. number of tokens the LLM sees per run.\n",
    "#     \"embDim\": 768, # Size of the internal. embeddings used in the LLM attention mechanism.\n",
    "#     \"nLayers\" : 6, # Number of transformer layers.\n",
    "#     \"dropRate\": 0.1, # Feature dropout rate.\n",
    "#     \"nHeads\": 12 # Num. Attention heads per multi-head attention block    \n",
    "# }\n",
    "\n",
    "model = GPTModel(cfg)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "076b3c7d",
   "metadata": {},
   "source": [
    "##### Run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9675e871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1 (Step 000000): Train loss 14.291, Val loss 8.248\n",
      "Ep 1 (Step 000005): Train loss 13.283, Val loss 7.733\n",
      "Every effort moves you                                                  \n",
      "Ep 2 (Step 000010): Train loss 12.395, Val loss 7.313\n",
      "Ep 2 (Step 000015): Train loss 11.685, Val loss 7.007\n",
      "Every effort moves you,                                                 \n",
      "Ep 3 (Step 000020): Train loss 11.161, Val loss 6.815\n",
      "Ep 3 (Step 000025): Train loss 10.754, Val loss 6.706\n",
      "Every effort moves you,                                                 \n",
      "Ep 4 (Step 000030): Train loss 10.391, Val loss 6.633\n",
      "Ep 4 (Step 000035): Train loss 10.072, Val loss 6.584\n",
      "Every effort moves you,                                               \",\n",
      "Ep 5 (Step 000040): Train loss 9.781, Val loss 6.545\n",
      "Every effort moves you,         \", and the                   \", and, and, and, the, and, and, and, and\n",
      "Ep 6 (Step 000045): Train loss 9.506, Val loss 6.496\n",
      "Ep 6 (Step 000050): Train loss 9.248, Val loss 6.464\n",
      "Every effort moves you,     \" a, and, and, the          \", and.     \", and, and, and, I had     \"--\n",
      "Ep 7 (Step 000055): Train loss 9.031, Val loss 6.463\n",
      "Ep 7 (Step 000060): Train loss 8.772, Val loss 6.441\n",
      "Every effort moves you,   \" of the   \"--. \"--.   \"--. \"----.    \"--, I had to. \".    \"----as\n",
      "Ep 8 (Step 000065): Train loss 8.502, Val loss 6.418\n",
      "Ep 8 (Step 000070): Train loss 8.236, Val loss 6.391\n",
      "Every effort moves you, I  \"I.   \"I, and he was.  \"--I \". I had been--and. \"I, and he was.      \"------as\n",
      "Ep 9 (Step 000075): Train loss 7.937, Val loss 6.361\n",
      "Ep 9 (Step 000080): Train loss 7.710, Val loss 6.372\n",
      "Every effort moves you, I  \" of the   \"Oh, the \"--I of the  \"--. I had been--and, and I was his   \"I of the \"I, and, and he\n",
      "Ep 10 (Step 000085): Train loss 7.480, Val loss 6.345\n",
      "Every effort moves you, I  \"Oh, and he \"Oh, the \"--and to the  \"--. I \"--and, I had been the    \" a, and he was, I had been to\n",
      "Ep 11 (Step 000090): Train loss 7.171, Val loss 6.328\n",
      "Ep 11 (Step 000095): Train loss 6.906, Val loss 6.324\n",
      "Every effort moves you, I  \"Oh, and he was a little I was his own.  \"--I was a, and he had--and, and he was his painting, and he was \"I of the, and he was his\n",
      "Ep 12 (Step 000100): Train loss 6.685, Val loss 6.312\n",
      "Ep 12 (Step 000105): Train loss 6.426, Val loss 6.346\n",
      "Every effort moves you know   \"Oh, with a in a little, the \"--and to me--I  \"--and. I was, I had been the_--and.      \"--the. \n",
      "Ep 13 (Step 000110): Train loss 6.127, Val loss 6.339\n",
      "Ep 13 (Step 000115): Train loss 5.910, Val loss 6.346\n",
      "Every effort moves you   \",, you know it \"Oh, to the of the he had been. \"Oh, I \"--and, I had been the_ he  the of the, and  \"Oh, and\n",
      "Ep 14 (Step 000120): Train loss 5.615, Val loss 6.337\n",
      "Ep 14 (Step 000125): Train loss 5.389, Val loss 6.318\n",
      "Every effort moves you  \", and, with a the \"Oh, to the \"I of it--and he was his it.  \"I the_ to the \"--the \"Oh, and, I had I \n",
      "Ep 15 (Step 000130): Train loss 5.221, Val loss 6.364\n",
      "Every effort moves you know I had \"Oh, and I \"Oh, the I of the \"Oh, with a little. \"--and that the_, I \"Oh, and. \"I He showed it to\n",
      "Ep 16 (Step 000135): Train loss 4.977, Val loss 6.354\n",
      "Ep 16 (Step 000140): Train loss 4.698, Val loss 6.401\n",
      "Every effort moves you know I had the room.  \"Oh, you to the--and in the \" of the donkey, I \"--and, you know. \"_--the's  \"Oh, he had it didn't \n",
      "Ep 17 (Step 000145): Train loss 4.435, Val loss 6.446\n",
      "Ep 17 (Step 000150): Train loss 4.236, Val loss 6.376\n",
      "Every effort moves you know I had the and.  \"Oh, you to my dear, he had been--and he had been the \"--and, you know it happened the light \"Oh, I had been a  \"I \n",
      "Ep 18 (Step 000155): Train loss 3.972, Val loss 6.419\n",
      "Ep 18 (Step 000160): Train loss 3.798, Val loss 6.435\n",
      "Every effort moves you know I had the room.  \"Oh, you to my dear, he had been--I felt to me to have been--and, you know; and I had \" of \"Oh, and in the Riviera to\n",
      "Ep 19 (Step 000165): Train loss 3.547, Val loss 6.478\n",
      "Ep 19 (Step 000170): Train loss 3.342, Val loss 6.488\n",
      "Every effort moves you know I had the room.  \"Oh, you know; and I said.  I was a little I had been--and, you know; and I had \"Oh of the \"I was a little I \n",
      "Ep 20 (Step 000175): Train loss 3.155, Val loss 6.505\n",
      "Every effort moves you know I had the room.  \"Oh, you know. \"Oh, a I said lightly; then, in the He _the_ fashionable painter--and to have of the house.\" \"By Jove--\n",
      "Ep 21 (Step 000180): Train loss 2.957, Val loss 6.515\n",
      "Ep 21 (Step 000185): Train loss 2.738, Val loss 6.541\n",
      "Every effort moves you know like.\" the-.  \"Oh, you know; and I said.  I was a sketch of a donkey--and, you know; and I seemed to see a smile, and Mrs. Gisburn--as\n",
      "Ep 22 (Step 000190): Train loss 2.562, Val loss 6.553\n",
      "Ep 22 (Step 000195): Train loss 2.454, Val loss 6.569\n",
      "Every effort moves you say to \"I her eyebrows with a \"Oh, I felt I had been \"Oh, he had been the \"--and yet not to have been the light through curtains of the house.\" \"By. Gis\n",
      "Ep 23 (Step 000200): Train loss 2.244, Val loss 6.596\n",
      "Ep 23 (Step 000205): Train loss 2.044, Val loss 6.625\n",
      "Every effort moves you know like.\" the room.  \"Oh, you it--I found the \"Oh, he had a  \"--and yet not to my dear I seemed to see a \"My dear, with a \"I\n",
      "Ep 24 (Step 000210): Train loss 1.919, Val loss 6.656\n",
      "Ep 24 (Step 000215): Train loss 1.731, Val loss 6.644\n",
      "Every effort moves you know like.\" the room.  \"Oh, by to wander up and down the  It was a sketch of a donkey--and, I looked up, I seemed to see a smile. \"I turned back of the air\n",
      "Ep 25 (Step 000220): Train loss 1.651, Val loss 6.707\n",
      "Every effort moves you know like.\" the room.  \"Oh, by Jove!\" I said.  It was a sketch of a donkey--and, you know, standing in the He was a wall.  \"By Jove--\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(),\n",
    "    lr=0.0004, weight_decay=0.1\n",
    ")\n",
    "num_epochs = 25\n",
    "train_losses, val_losses, tokens_seen = train_model_simple(\n",
    "    model, train_loader, val_loader, optimizer, device,\n",
    "    num_epochs=num_epochs, eval_freq=5, eval_iter=5,\n",
    "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a2f0a3",
   "metadata": {},
   "source": [
    "##### Display Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5b56112a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "def _to_list(x):\n",
    "    if torch.is_tensor(x):\n",
    "        # avoids .numpy() so no NumPy dependency\n",
    "        return x.detach().cpu().tolist()\n",
    "    # handle lists/tuples already\n",
    "    return x\n",
    "\n",
    "\n",
    "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
    "    ax1.plot(\n",
    "        epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\"\n",
    "    )\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Loss\")\n",
    "    ax1.legend(loc=\"upper right\")\n",
    "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    ax2 = ax1.twiny()\n",
    "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
    "    ax2.set_xlabel(\"Tokens seen\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "plot_losses(_to_list(epochs_tensor), _to_list(tokens_seen), _to_list(train_losses), _to_list(val_losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e66834e",
   "metadata": {},
   "source": [
    "##### Generate new output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "313413eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The it really was a tempting problem. To accuse his wife would have been too easy--his \"Oh  It was a sketch of a donkey--and yet not to see it happened? I can tell you in the donkey--and it\n"
     ]
    }
   ],
   "source": [
    "generate_and_print_sample(model, tokenizer, device, \"The\", top_k=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e9ec8e",
   "metadata": {},
   "source": [
    "### Save Model State"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a3bbd5",
   "metadata": {},
   "source": [
    "Store the model state (weights) and optimizer state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "96e3b0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    \"model_state_dict\": model.state_dict(),\n",
    "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "    },\n",
    "    \"model_and_optimizer.pth\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336c4f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"model_and_optimizer.pth\", map_location=device)\n",
    "model = GPTModel(cfg)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4, weight_decay=0.1)\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
